{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import loguniform\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn import neural_network\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import validation_curve\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout \n",
    "# from tensorflow.keras.layers import BatchNormalization \n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint # new!\n",
    "import os # new!\n",
    "# import seaborn as sns\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout \n",
    "# from tensorflow.keras.layers import BatchNormalization \n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint # new!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "box_plot_title = 'Memory Estimation Error (MB)'\n",
    "pd.set_option('display.max_columns', None)\n",
    "# cluster_set = [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('job2_scaled_clean.csv')\n",
    "    # df_test = pd.read_csv('job2_test_clean.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train and Evaluate a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(estimator, batch_size, X, Y):\n",
    "    predicted = estimator.predict(X)\n",
    "    Y = np.insert(Y, Y.shape[1], predicted, axis=1)\n",
    "    \n",
    "    indices = np.linspace(0, X.shape[0]-1, X.shape[0], dtype=int)\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "    num_batches = int(np.floor(X.shape[0] / batch_size))\n",
    "    \n",
    "    df_batches = pd.DataFrame(columns=['actual', 'db2', 'ml'])\n",
    "    \n",
    "    for ibat in range(num_batches):\n",
    "        start = (ibat * batch_size)\n",
    "        end = (ibat * batch_size + batch_size) - 1\n",
    "        \n",
    "        ibat_Y = Y[indices[start:end]]\n",
    "        \n",
    "        actual = sum(ibat_Y[:,-1])\n",
    "        db2 = sum(ibat_Y[:,-2])\n",
    "        ml = sum(ibat_Y[:,-3])\n",
    "        \n",
    "        df_batches = df_batches.append({'actual':actual,\n",
    "                                       'db2':db2,\n",
    "                                       'ml':ml},\n",
    "                                      ignore_index=True)\n",
    "        \n",
    "    return df_batches\n",
    "\n",
    "def rmse(Y):\n",
    "    cols = Y.columns.values[1:]\n",
    "    rmse_dict = {}\n",
    "    \n",
    "    for col in cols:\n",
    "        rmse = np.round(np.sqrt(mean_squared_error(Y['actual'].values, Y[col].values)))\n",
    "        rmse_dict[col] = rmse\n",
    "    \n",
    "    return rmse_dict\n",
    "    \n",
    "def calculate_residuals(Y):\n",
    "    first_col = Y.columns[0]\n",
    "    cols = Y.columns[1:]\n",
    "    df_residuals = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for col in cols:\n",
    "        df_residuals[col] = Y[col] - Y[first_col]\n",
    "        \n",
    "    return df_residuals\n",
    "\n",
    "def box_plot(Y, length, height):\n",
    "    df_residuals = calculate_residuals(Y)\n",
    "    sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "    f = plt.figure(figsize=[length,height])\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    ax = f.add_subplot(111)\n",
    "    sns.boxplot(data=df_residuals, ax=ax, showfliers = True, orient=\"h\")\n",
    "    ax.set_xlabel(xlabel=box_plot_title,fontsize=22)\n",
    "    plt.tick_params(axis='x',labeltop='on', labelbottom='on')\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    #ax.set_yticks(yticks_new)\n",
    "#     plt.setp(ax.get_yticklabels(), rotation=90)\n",
    "    f.tight_layout()\n",
    "    plt.show()\n",
    "    ax.savefig('job_err.png')\n",
    "def residual_plot(Y):\n",
    "    Y_predicted = Y.iloc[:,1:]\n",
    "    print('Y_predicted ', Y_predicted.shape)\n",
    "    cols = Y_predicted.columns\n",
    "    markers = ['8', 'P', '*', 'h', 'X','+','^','s','o']\n",
    "#     colors = ['steelblue', 'darkorange', 'darkorchid', 'limegreen', 'fuchsia']\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(cols)))\n",
    "    \n",
    "    Y_residuals = calculate_residuals(Y)\n",
    "    print('Y_residuals ', Y_residuals.shape)\n",
    "    \n",
    "    for col in cols:\n",
    "        plot_index = Y_predicted.columns.get_loc(col)\n",
    "        plt.scatter(Y_predicted[col], Y_residuals[col], \n",
    "                   edgecolor='white', c=colors[plot_index],\n",
    "                   marker=markers[plot_index], label=col)\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.hlines(y=0, xmin=0, xmax=9000, color='black', lw=2)\n",
    "    plt.xlim([0, 9000])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(k, data, km):\n",
    "    X = data.drop(columns=['db2', 'actual'])\n",
    "    \n",
    "    if km is not None:\n",
    "        print('clustering test dataset')\n",
    "        y_kmeans = km.predict(X)\n",
    "    else:\n",
    "        print('clustering train dataset')\n",
    "        km = KMeans(\n",
    "            n_clusters=k, \n",
    "            init='k-means++', \n",
    "            n_init=10, \n",
    "            max_iter=300, \n",
    "            random_state=0\n",
    "        )\n",
    "        km.fit(X)\n",
    "        y_kmeans = km.predict(X)\n",
    "\n",
    "    print('Distortion: %.2f' % km.inertia_)\n",
    "    \n",
    "    df = data.copy()\n",
    "    df['cluster'] = y_kmeans  # Directly assign the entire array (more efficient)\n",
    "    df['cluster'] = df['cluster'].astype('int64')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_workload(batch_size, data):\n",
    "    # Select relevant columns\n",
    "    df_data = data[['db2', 'actual', 'cluster']]\n",
    "    \n",
    "    labels = df_data['cluster'].unique()\n",
    "    labels = np.sort(labels)\n",
    "    cluster_columns = [f\"cluster_{int(c)}\" for c in labels]\n",
    "    \n",
    "    # If df_data came from a filter like df_clusters_pruned[df_clusters_pruned[\"…\"]]\n",
    "    df_data = df_data.copy()                    # break the view‑link\n",
    "\n",
    "    df_data.loc[:, \"cluster\"] = df_data[\"cluster\"].astype(\"int64\")  # safe\n",
    "    df_data = pd.get_dummies(df_data, columns=[\"cluster\"], dtype=int)\n",
    "\n",
    "    # # cluster_columns = [f'cluster_{i}.0' for i in range(k)]\n",
    "    \n",
    "    missing_columns = [col for col in cluster_columns if col not in df_data.columns]\n",
    "    if missing_columns:\n",
    "        # Create a DataFrame with missing columns set to 0\n",
    "        df_missing = pd.DataFrame(0, index=df_data.index, columns=missing_columns)\n",
    "        # Concatenate the missing columns\n",
    "        df_data = pd.concat([df_data, df_missing], axis=1)\n",
    "\n",
    "    # Sort columns to maintain a consistent order (optional)\n",
    "    df_data = df_data.reindex(columns=['db2', 'actual'] + cluster_columns)\n",
    "    \n",
    "    # Initialize batches\n",
    "    df_batches = []\n",
    "    indices = np.arange(len(df_data))\n",
    "    num_batches = len(df_data) // batch_size\n",
    "    \n",
    "    # Create batches\n",
    "    for ibat in range(num_batches):\n",
    "        batch_indices = indices[ibat * batch_size:(ibat + 1) * batch_size]\n",
    "        ibat_Y = df_data.iloc[batch_indices]\n",
    "        df_batches.append(ibat_Y.sum())\n",
    "\n",
    "    # Combine batches into a DataFrame\n",
    "    return pd.DataFrame(df_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "df_clusters = get_clusters(k, df, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters[\"cluster\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of rows in each cluster\n",
    "cluster_counts = df_clusters[\"cluster\"].value_counts().sort_index()\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(cluster_counts.index, cluster_counts.values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Number of Rows\")\n",
    "plt.title(\"Distribution of Rows by Cluster\")\n",
    "plt.xticks(cluster_counts.index)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune templates with 10 or fewer queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1️⃣  Choose a threshold --------------------------------------------------\n",
    "min_rows = 10                     # keep clusters that have ≥ 50 rows\n",
    "# -- or, keep clusters that represent at least 1 % of the data —\n",
    "# min_rows = int(0.01 * len(df_clusters))\n",
    "\n",
    "# 2️⃣  Identify the clusters to keep --------------------------------------\n",
    "cluster_counts = df_clusters[\"cluster\"].value_counts()      # rows per cluster\n",
    "keep_clusters  = cluster_counts[cluster_counts >= min_rows].index\n",
    "\n",
    "# 3️⃣  Create the pruned DataFrame ----------------------------------------\n",
    "df_clusters_pruned = df_clusters[df_clusters[\"cluster\"].isin(keep_clusters)].copy()\n",
    "\n",
    "# (optional) reset row index\n",
    "df_clusters_pruned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# (optional) re‑label clusters so they’re 0, 1, 2, … again\n",
    "# mapping = {old:i for i, old in enumerate(sorted(keep_clusters))}\n",
    "# df_clusters_pruned[\"cluster\"] = df_clusters_pruned[\"cluster\"].map(mapping)\n",
    "\n",
    "print(f\"Kept {len(keep_clusters)} clusters, \"\n",
    "      f\"{len(df_clusters_pruned)} of {len(df_clusters)} total rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of rows in each cluster\n",
    "cluster_counts = df_clusters_pruned[\"cluster\"].value_counts().sort_index()\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(cluster_counts.index, cluster_counts.values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Number of Rows\")\n",
    "plt.title(\"Distribution of Rows by Cluster\")\n",
    "plt.xticks(cluster_counts.index)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters_pruned[\"cluster\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def split_clusters(\n",
    "    df: pd.DataFrame,\n",
    "    cluster_col: str = \"cluster\",\n",
    "    train_frac: float = 0.80,      # 0.80 if you want 80 / 20\n",
    "    seed: int | None = 42          # set to any int for repeatability, or None\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split *df* into train/test by assigning whole clusters to one side only.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain the cluster label column.\n",
    "    cluster_col : str, default \"cluster\"\n",
    "    train_frac : float, default 0.50\n",
    "        Fraction of clusters to send to the training partition.\n",
    "    seed : int or None, default 42\n",
    "        Seed for the RNG.  Different seed ⇒ different split.\n",
    "        Use None for a new random split every run.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_train, df_test : Tuple[pd.DataFrame, pd.DataFrame]\n",
    "    \"\"\"\n",
    "    # 1️⃣  Unique clusters\n",
    "    unique_clusters = df[cluster_col].unique()\n",
    "\n",
    "    # 2️⃣  Shuffle with a controllable seed\n",
    "    rng = np.random.default_rng(seed)\n",
    "    shuffled = rng.permutation(unique_clusters)\n",
    "\n",
    "    # 3️⃣  Split by the desired fraction\n",
    "    n_train = max(1, int(round(train_frac * len(shuffled))))\n",
    "    train_clusters = shuffled[:n_train]\n",
    "    test_clusters  = shuffled[n_train:]\n",
    "\n",
    "    # 4️⃣  Build the partitions\n",
    "    df_train = df[df[cluster_col].isin(train_clusters)].copy()\n",
    "    df_test  = df[df[cluster_col].isin(test_clusters)].copy()\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "seeds = [123, 234, 456, 567, 678]\n",
    "\n",
    "# ─── Example usage ─────────────────────────────────────────────────────────\n",
    "df_train, df_test = split_clusters(\n",
    "    df_clusters_pruned,     # your DataFrame\n",
    "    train_frac=0.80,        # 50 / 50; use 0.80 for 80 / 20, etc.\n",
    "    seed=seeds[2]                # change → different clusters in each side\n",
    ")\n",
    "\n",
    "print(f\"Train rows: {len(df_train)}, Test rows: {len(df_test)}\")\n",
    "print(f\"Unique train clusters: {df_train['cluster'].nunique()}, \"\n",
    "          f\"Test clusters: {df_test['cluster'].nunique()}\")\n",
    "\n",
    "print(f\"Train clusters: {sorted(df_train['cluster'].unique())}\")\n",
    "print(f\"Test clusters:  {sorted(df_test['cluster'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the folder exists\n",
    "output_folder = \"cluster_data\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "df_train_workloads = create_workload(batch_size, df_train)\n",
    "df_test_workloads = create_workload(batch_size, df_test)\n",
    "\n",
    "# for k in cluster_set:\n",
    "#     km, df_clusters = get_clusters(k, df, None)\n",
    "    \n",
    "#     workload_train = create_workload(batch_size, df_train_clusters, k)\n",
    "#     # workload_test = create_workload(batch_size, df_test_clusters, k)\n",
    "\n",
    "#     file_name_train = os.path.join(output_folder, f'train_workloads_final_{k}_clusters.csv')\n",
    "#     # file_name_test = os.path.join(output_folder, f'test_workloads_final_{k}_clusters.csv')\n",
    "    \n",
    "#     workload_train.to_csv(file_name_train, index=False)\n",
    "#     # workload_test.to_csv(file_name_test, index=False)\n",
    "    \n",
    "#     print(f\"k = {k} is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_workloads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_workloads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_workloads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_workloads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_workloads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_workloads.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "align the two frames on their columns and tell pandas to fill anything that’s missing with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1️⃣  Align the two frames on their columns (outer join) -------------\n",
    "df_train_workloads, df_test_workloads = (\n",
    "    df_train_workloads.align(\n",
    "        df_test_workloads,\n",
    "        join=\"outer\",      # union of columns\n",
    "        axis=1,            # align on columns\n",
    "        fill_value=0       # 0 for every newly created cell\n",
    "    )\n",
    ")\n",
    "\n",
    "# ---- 2️⃣  Move 'db2' and 'actual' to the front ---------------------------\n",
    "def move_metrics_first(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    front = [\"db2\", \"actual\"]\n",
    "    rest  = [c for c in df.columns if c not in front]\n",
    "    return df[front + rest]\n",
    "\n",
    "df_train_workloads = move_metrics_first(df_train_workloads)\n",
    "df_test_workloads  = move_metrics_first(df_test_workloads)\n",
    "\n",
    "# ---- 3️⃣  (Optional) cast the dummy columns back to int ------------------\n",
    "for df in (df_train_workloads, df_test_workloads):\n",
    "    dummy_cols = [c for c in df.columns if c.startswith(\"cluster_\")]\n",
    "    df[dummy_cols] = df[dummy_cols].astype(np.int8)   # or int64 / Int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_workloads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_workloads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_workloads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate that each row in both dataframes has exactly 5 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Adjust once here if your batch size ever changes.\n",
    "BATCH_SIZE = 5\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def validate_cluster_counts(df: pd.DataFrame, batch_size: int = BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Ensure the dummy cluster columns in *df* sum to *batch_size* in every row.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns named 'cluster_*'.\n",
    "    batch_size : int, default 5\n",
    "        The expected row‑sum across cluster_* columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A view of any rows that violate the rule (empty → everything is OK).\n",
    "    \"\"\"\n",
    "    cluster_cols = [c for c in df.columns if c.startswith(\"cluster_\")]\n",
    "    if not cluster_cols:\n",
    "        raise ValueError(\"No columns named 'cluster_*' found\")\n",
    "\n",
    "    wrong_rows = df[np.abs(df[cluster_cols].sum(axis=1) - batch_size) > 0]\n",
    "    return wrong_rows\n",
    "\n",
    "\n",
    "# --- Example usage ---------------------------------------------------------\n",
    "bad_train = validate_cluster_counts(df_train_workloads)  # rows whose sum ≠ 5\n",
    "bad_test  = validate_cluster_counts(df_test_workloads)\n",
    "\n",
    "if bad_train.empty and bad_test.empty:\n",
    "    print(\"✅ Every row sums to 5 — both DataFrames are consistent.\")\n",
    "else:\n",
    "    print(f\"🚩 Train rows off‑total:\\n{bad_train.index.tolist()}\")\n",
    "    print(f\"🚩 Test  rows off‑total:\\n{bad_test.index.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_workloads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_workloads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_train_data():\n",
    "    df = df_train_workloads\n",
    "    \n",
    "    feature_cols = [col for col in df.columns if col.startswith('cluster_')]    \n",
    "    print(feature_cols)\n",
    "\n",
    "    target_col = ['actual']\n",
    "    \n",
    "    X = df[feature_cols]\n",
    "    y = df[target_col].values.ravel()  # Flatten y to 1D\n",
    "    \n",
    "    print('X.shape: ', X.shape)\n",
    "    print('y.shape: ', y.shape)\n",
    "    \n",
    "    return X.values, y\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    df = df_test_workloads\n",
    "  \n",
    "    # Assuming `df` is your DataFrame\n",
    "    feature_cols = [col for col in df.columns if col.startswith('cluster_')]\n",
    "    print(feature_cols)\n",
    "    \n",
    "    target_cols = ['db2', 'actual']\n",
    "    \n",
    "    X = df[feature_cols]\n",
    "    Y = df[target_cols]\n",
    "    \n",
    "    print('X.shape: ', X.shape)\n",
    "    print('y.shape: ', y.shape)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def my_validation_curve(estimator_name, estimator, param_name, param_range):\n",
    "    train_scores, valid_scores = validation_curve(estimator, X, y, param_name=param_name,\n",
    "        param_range=param_range, cv=10, scoring=\"neg_mean_squared_error\",\n",
    "    )\n",
    "\n",
    "    train_scores = np.sqrt(np.abs(train_scores))\n",
    "    valid_scores = np.sqrt(np.abs(valid_scores))\n",
    "    \n",
    "    print(len(train_scores))\n",
    "    print(len(valid_scores))\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "    \n",
    "    title_str = \"Validation Curve with \" + estimator_name\n",
    "    plt.title(title_str)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.plot(param_range, train_scores_mean, label=\"train rmse\")\n",
    "    plt.plot(param_range, valid_scores_mean, label=\"validation rmse\")\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    train_rmse = [round(elem, 2) for elem in train_scores_mean]\n",
    "    valid_rmse = [round(elem, 2) for elem in valid_scores_mean]\n",
    "    \n",
    "    df_scores = pd.DataFrame({'param': param_range, 'train_rmse': train_rmse, 'valid_rmse': valid_rmse})\n",
    "    print(df_scores)\n",
    "    \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def cross_validate(model):\n",
    "    # Load data\n",
    "    X, y = load_train_data()\n",
    "    train_data = X.copy()\n",
    "    train_targets = y.copy()\n",
    "\n",
    "    k = 10\n",
    "    num_val_samples = len(train_data) // k\n",
    "    all_train_scores = []\n",
    "    all_scores = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        print(f\"Processing fold #{i}\")\n",
    "        val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        \n",
    "        partial_train_data = np.concatenate([train_data[:i * num_val_samples],\n",
    "                                             train_data[(i + 1) * num_val_samples:]], axis=0)\n",
    "        \n",
    "        partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],\n",
    "                                                train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
    "\n",
    "        model.fit(partial_train_data, partial_train_targets)\n",
    "    \n",
    "        train_mse = mean_squared_error(partial_train_targets, model.predict(partial_train_data))\n",
    "        val_mse = mean_squared_error(val_targets, model.predict(val_data))\n",
    "    \n",
    "        all_train_scores.append(train_mse)\n",
    "        all_scores.append(val_mse)\n",
    "    \n",
    "    train_rmse = np.sqrt(np.mean(all_train_scores))\n",
    "    val_rmse = np.sqrt(np.mean(all_scores))\n",
    "\n",
    "    print('train rmse:', train_rmse)\n",
    "    print('validation rmse:', val_rmse)\n",
    "\n",
    "    return train_rmse, val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Cross-Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(\n",
    "        fit_intercept=True, \n",
    "        solver='lsqr',\n",
    "        alpha = 1.0,\n",
    "        random_state=42)\n",
    "\n",
    "rmse_scores['Ridge'] = cross_validate(ridge)\n",
    "# ridge.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression - Tuning max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(\n",
    "    max_depth=5,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=0.23,\n",
    "    random_state=33,\n",
    ")\n",
    "\n",
    "rmse_scores['Decision Tree'] = cross_validate(tree)\n",
    "\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest final model - using tuned HP from AutoAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(\n",
    "    max_depth=5,\n",
    "    max_features=0.6109469920813564,\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=17,\n",
    "    #n_jobs=CPU_NUMBER,\n",
    "    random_state=33,\n",
    ")\n",
    "\n",
    "rmse_scores['Random Forest'] = cross_validate(forest)\n",
    "\n",
    "forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_regressor = XGBRegressor(\n",
    "    # --- general ----------------------------------------------------------\n",
    "    objective=\"reg:squarederror\",        # default for regression\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    random_state=33,                     # controls all randomness\n",
    "    seed=33,                             # still accepted (alias for random_state)\n",
    "\n",
    "    # --- tree construction ------------------------------------------------\n",
    "    tree_method=\"hist\",                  # faster than \"exact\" on most CPUs\n",
    "    device=\"cpu\",                        # set to \"cuda\" for GPU training ➊\n",
    "    n_jobs=1,                            # threads (was `nthread`) ➋\n",
    "    n_estimators=879,\n",
    "    learning_rate=0.1814227666290778,\n",
    "    max_depth=1,\n",
    "    min_child_weight=2,\n",
    "    max_delta_step=0,\n",
    "\n",
    "    # --- column / row sampling -------------------------------------------\n",
    "    subsample=0.04694370939809412,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "\n",
    "    # --- regularisation ---------------------------------------------------\n",
    "    gamma=0.0,                           # alias for `min_split_loss`\n",
    "    reg_alpha=1.0,\n",
    "    reg_lambda=0.40529327440922186,\n",
    "\n",
    "    # --- misc -------------------------------------------------------------\n",
    "    interaction_constraints=\"\",\n",
    "    monotone_constraints=\"()\",\n",
    "    num_parallel_tree=1,\n",
    "    scale_pos_weight=1,\n",
    "    verbosity=0,                         # replaces deprecated `silent` ➌\n",
    "    validate_parameters=True,            # still supported ➍\n",
    ")\n",
    "\n",
    "\n",
    "rmse_scores['XGBoost'] = cross_validate(xgb_regressor)\n",
    "\n",
    "xgb_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "dnn_model = dnn_model = MLPRegressor(max_iter=500,\n",
    "                     alpha=0.001,\n",
    "                     activation='identity',\n",
    "                     learning_rate= 'constant',\n",
    "                     random_state = 6,\n",
    "                     hidden_layer_sizes = (48, 39, 27, 16, 7, 5),\n",
    "                     solver = 'lbfgs'\n",
    "                    )\n",
    "rmse_scores['DNN'] = cross_validate(dnn_model)\n",
    "\n",
    "dnn_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Your RMSE results for each model\n",
    "# rmse_scores = {\n",
    "#     'DNN': (29.99, 33.11),\n",
    "#     'XGBoost': (25.12, 26.80),\n",
    "#     'Random Forest': (23.87, 25.43),\n",
    "#     'Decision Tree': (24.55, 27.36),\n",
    "#     'Ridge': (27.01, 29.42)\n",
    "# }\n",
    "\n",
    "# Extract model names and RMSE values\n",
    "model_names = list(rmse_scores.keys())\n",
    "train_rmses = [rmse_scores[model][0] for model in model_names]\n",
    "val_rmses = [rmse_scores[model][1] for model in model_names]\n",
    "\n",
    "# Identify the best model (lowest validation RMSE)\n",
    "best_index = val_rmses.index(min(val_rmses))\n",
    "\n",
    "# Plot setup\n",
    "x = range(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Color settings\n",
    "train_colors = ['#a6cee3' if i != best_index else '#1f9e44' for i in x]\n",
    "val_colors = ['#fdbf6f' if i != best_index else '#1f9e44' for i in x]\n",
    "\n",
    "# Draw bars\n",
    "train_bars = ax.bar([i - width/2 for i in x], train_rmses, width, label='Train RMSE', color=train_colors)\n",
    "val_bars = ax.bar([i + width/2 for i in x], val_rmses, width, label='Validation RMSE', color=val_colors)\n",
    "\n",
    "# Add RMSE value labels on top of bars\n",
    "for bar_group in [train_bars, val_bars]:\n",
    "    for bar in bar_group:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Annotate \"⬇ Best Model\" below the best model label, slightly higher for spacing\n",
    "ax.text(\n",
    "    best_index,\n",
    "    -1,  # Higher than before (-2)\n",
    "    '⬇ Best Model',\n",
    "    ha='center',\n",
    "    va='top',\n",
    "    fontsize=10,\n",
    "    color='#1f9e44',\n",
    "    fontweight='bold'\n",
    ")\n",
    "\n",
    "# Formatting and labels\n",
    "ax.set_ylabel('RMSE', fontsize=12)\n",
    "ax.set_title('Train vs Validation RMSE by Model', fontsize=14, weight='bold')\n",
    "ax.set_xticks(list(x))\n",
    "ax.set_xticklabels(model_names, rotation=15, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Adjust y-limits to make space for bottom label\n",
    "ax.set_ylim(\n",
    "    bottom=min(min(train_rmses), min(val_rmses)) - 4,\n",
    "    top=max(max(train_rmses), max(val_rmses)) + 5\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test.copy()\n",
    "Y_test['dnn'] = dnn_model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'actual' is the first column\n",
    "cols = ['actual'] + [col for col in Y_test.columns if col != 'actual']\n",
    "Y_test = Y_test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# MAPE for db2\n",
    "mape_db2 = mean_absolute_percentage_error(Y_test['actual'], Y_test['db2'])\n",
    "\n",
    "# MAPE for dnn\n",
    "mape_dnn = mean_absolute_percentage_error(Y_test['actual'], Y_test['dnn'])\n",
    "\n",
    "print(f\"MAPE (db2): {mape_db2:.3f}%\")\n",
    "print(f\"MAPE (dnn): {mape_dnn:.3f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

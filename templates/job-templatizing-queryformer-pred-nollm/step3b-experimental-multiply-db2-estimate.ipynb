{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a single query model using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import loguniform\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn import neural_network\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import os # new!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "box_plot_title = 'Memory Estimation Error (MB)'\n",
    "pd.set_option('display.max_columns', None)\n",
    "cluster_set = [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_success = pd.read_csv('utils/success_db2_est.csv')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df_success.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the JSON file\n",
    "val_embeddings_path = \"val_embeddings.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(val_embeddings_path, \"r\") as f:\n",
    "    val_embeddings_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "val_embeddings_df = pd.DataFrame({\n",
    "    \"file_name\": list(val_embeddings_data.keys()),\n",
    "    \"embedding\": list(val_embeddings_data.values())\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(val_embeddings_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract QUERYID and EXPLAIN_TIME\n",
    "val_embeddings_df[\"QUERYID\"] = val_embeddings_df[\"file_name\"].apply(lambda x: x.split(\"_\")[1])\n",
    "val_embeddings_df[\"EXPLAIN_TIME\"] = val_embeddings_df[\"file_name\"].apply(lambda x: x.split(\"_\")[2].replace(\".pt\", \"\"))\n",
    "\n",
    "# Convert QUERYID to integer (if needed)\n",
    "val_embeddings_df[\"QUERYID\"] = val_embeddings_df[\"QUERYID\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming val_embeddings_df and df_success are already defined\n",
    "\n",
    "# Perform the join\n",
    "result_df = pd.merge(\n",
    "    val_embeddings_df,\n",
    "    df_success,\n",
    "    on=['QUERYID', 'EXPLAIN_TIME'],  # Match on QUERYID and EXPLAIN_TIME\n",
    "    how='inner'  # Inner join to keep only matching rows\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(result_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = result_df.copy()[['embedding', 'SORT_SHRHEAP_TOP', 'Db2_ESTIMATE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the JSON file\n",
    "train_embeddings_path = \"train_embeddings.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(train_embeddings_path, \"r\") as f:\n",
    "    train_embeddings_path_embeddings_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_embeddings_df = pd.DataFrame({\n",
    "    \"file_name\": list(train_embeddings_path_embeddings_data.keys()),\n",
    "    \"embedding\": list(train_embeddings_path_embeddings_data.values())\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "# print(train_embeddings_path_embeddings_df.head())\n",
    "\n",
    "# Extract QUERYID and EXPLAIN_TIME\n",
    "train_embeddings_df[\"QUERYID\"] = train_embeddings_df[\"file_name\"].apply(lambda x: x.split(\"_\")[1])\n",
    "train_embeddings_df[\"EXPLAIN_TIME\"] = train_embeddings_df[\"file_name\"].apply(lambda x: x.split(\"_\")[2].replace(\".pt\", \"\"))\n",
    "\n",
    "# Convert QUERYID to integer (if needed)\n",
    "train_embeddings_df[\"QUERYID\"] = train_embeddings_df[\"QUERYID\"].astype(int)\n",
    "\n",
    "# Perform the join\n",
    "result_df = pd.merge(\n",
    "    train_embeddings_df,\n",
    "    df_success,\n",
    "    on=['QUERYID', 'EXPLAIN_TIME'],  # Match on QUERYID and EXPLAIN_TIME\n",
    "    how='inner'  # Inner join to keep only matching rows\n",
    ")\n",
    "\n",
    "df_train = result_df.copy()[['embedding', 'SORT_SHRHEAP_TOP', 'Db2_ESTIMATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for df_train\n",
    "df_train.rename(columns={\n",
    "    'embedding': 'sql_embedding',\n",
    "    'SORT_SHRHEAP_TOP': 'actual',\n",
    "    'Db2_ESTIMATE': 'db2'\n",
    "}, inplace=True)\n",
    "\n",
    "df_train = df_train[['sql_embedding', 'db2', 'actual']]\n",
    "\n",
    "# Rename columns for df_test\n",
    "df_test.rename(columns={\n",
    "    'embedding': 'sql_embedding',\n",
    "    'SORT_SHRHEAP_TOP': 'actual',\n",
    "    'Db2_ESTIMATE': 'db2'\n",
    "}, inplace=True)\n",
    "\n",
    "df_test = df_test[['sql_embedding', 'db2', 'actual']]\n",
    "\n",
    "# Verify the changes\n",
    "print(df_train.head())\n",
    "print(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['db2'] = df_train['db2'] * 4000 / 1000000\n",
    "df_train['actual'] = df_train['actual'] * 4000 / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['db2'] = df_test['db2'] * 4000 / 1000000\n",
    "df_test['actual'] = df_test['actual'] * 4000 / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['sql_embedding', 'actual']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['db2', 'actual']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Multiply each embedding vector by the corresponding scalar in db2\n",
    "df['sql_embedding'] = df.apply(lambda row: (np.array(row['sql_embedding']) * row['db2']).tolist(), axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Keep 'combined_embedding' as a DataFrame column to retain indexing\n",
    "X = df[['sql_embedding']]  \n",
    "y = df['actual']\n",
    "\n",
    "# Split the data while retaining DataFrame structure\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert combined embedding column to NumPy arrays after splitting\n",
    "X_train = np.vstack(X_train['sql_embedding'].values)\n",
    "X_test = np.vstack(X_test['sql_embedding'].values)\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "model = XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the XGBoost model\n",
    "xgb_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
    "xgb_mape = mean_absolute_percentage_error(y_test, xgb_pred)\n",
    "\n",
    "# Ensure 'db2' predictions are aligned with the test indices\n",
    "db2_test_pred = df.loc[y_test.index, 'db2'].values\n",
    "\n",
    "# Evaluate 'db2' predictions\n",
    "db2_rmse = np.sqrt(mean_squared_error(y_test, db2_test_pred))\n",
    "db2_mape = mean_absolute_percentage_error(y_test, db2_test_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'XGBoost Model - RMSE: {xgb_rmse:.2f}, MAPE: {xgb_mape:.2%}')\n",
    "print(f'db2 Predictions - RMSE: {db2_rmse:.2f}, MAPE: {db2_mape:.2%}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from model.database_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.util import Normalizer\n",
    "\n",
    "# cost_norm = Normalizer(1, 100)\n",
    "# cost_norm = Normalizer(-3.61192, 12.290855)\n",
    "#cost_norm = Normalizer(5, 2611)\n",
    "cost_norm = Normalizer(8.26, 11.12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # bs = 1024\n",
    "    # SQ: smaller batch size\n",
    "    bs = 1\n",
    "    #lr = 0.001\n",
    "    lr = 0.001\n",
    "    # epochs = 200\n",
    "    epochs = 50\n",
    "    clip_size = 50\n",
    "    embed_size = 64\n",
    "    pred_hid = 128\n",
    "    ffn_dim = 128\n",
    "    head_size = 12\n",
    "    n_layers = 8\n",
    "    dropout = 0.1\n",
    "    sch_decay = 0.6\n",
    "    # device = 'cuda:0'\n",
    "    device = 'cpu'\n",
    "    newpath = 'job_queries_training'\n",
    "    to_predict = 'cost'\n",
    "args = Args()\n",
    "\n",
    "import os\n",
    "if not os.path.exists(args.newpath):\n",
    "    os.makedirs(args.newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import QueryFormer\n",
    "\n",
    "model = QueryFormer(emb_size = args.embed_size ,ffn_dim = args.ffn_dim, head_size = args.head_size, \\\n",
    "                 dropout = args.dropout, n_layers = args.n_layers, \\\n",
    "                 use_sample = False, use_hist = False, \\\n",
    "                 pred_hid = args.pred_hid\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataset import PlanTreeDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([1, 30, 1161])\n",
      "rel_pos shape: torch.Size([1, 30, 30])\n",
      "attn_bias shape: torch.Size([1, 31, 31])\n",
      "heights shape: torch.Size([1, 30])\n",
      "cost_labels shape: torch.Size([1])\n",
      "raw_costs shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Load the saved tensor collection\n",
    "loaded_tensors = torch.load(\"./job_queries/tensors/query_1_2024-12-03-20.43.44.200877.pt\")\n",
    "\n",
    "# Access each tensor\n",
    "x_loaded = loaded_tensors[\"x\"]\n",
    "rel_pos_loaded = loaded_tensors[\"rel_pos\"]\n",
    "attn_bias_loaded = loaded_tensors[\"attn_bias\"]\n",
    "heights_loaded = loaded_tensors[\"heights\"]\n",
    "cost_labels_loaded = loaded_tensors[\"cost_labels\"]\n",
    "raw_costs_loaded = loaded_tensors[\"raw_costs\"]\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(f\"x shape: {x_loaded.shape}\")\n",
    "print(f\"rel_pos shape: {rel_pos_loaded.shape}\")\n",
    "print(f\"attn_bias shape: {attn_bias_loaded.shape}\")\n",
    "print(f\"heights shape: {heights_loaded.shape}\")\n",
    "print(f\"cost_labels shape: {cost_labels_loaded.shape}\")\n",
    "print(f\"raw_costs shape: {raw_costs_loaded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.,  ..., 1., 1., 1.],\n",
       "         [2., 0., 0.,  ..., 1., 1., 1.],\n",
       "         [3., 1., 0.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4,  4,  5,  5,  6,  6,  7,  8,  8,  9, 10, 10, 11, 11,\n",
       "           9,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61,  1,  2,  3,  3,  4,  4,  5,  5,  6,  7,  7,  8,  9,  9, 10, 10,\n",
       "           8,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61,  1,  2,  2,  3,  3,  4,  4,  5,  6,  6,  7,  8,  8,  9,  9,\n",
       "           7,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61,  1, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
       "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61,  1,  2,  2,  3,  3,  4,  5,  5,  6,  7,  7,  8,  8,\n",
       "           6,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61,  1, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
       "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61,  1,  2,  2,  3,  4,  4,  5,  6,  6,  7,  7,\n",
       "           5,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61,  1, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
       "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  3,  3,  4,  5,  5,  6,  6,\n",
       "           4,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  2,  3,  4,  4,  5,  5,\n",
       "           3, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1, 61, 61, 61, 61, 61, 61,\n",
       "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  3,  3,  4,  4,\n",
       "           2, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  2,  3,  3,\n",
       "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1, 61, 61, 61,\n",
       "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  2,\n",
       "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1, 61,\n",
       "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,\n",
       "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
       "           1, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
       "          61,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_pos_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
       "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_bias_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 11, 10,  2,  9,  2,  8,  2,  7,  6,  2,  2,  5,  4,  2,  2,  3,  2,\n",
       "          2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heights_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([66844.], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_costs_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9965], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_labels_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([1, 30, 1161])\n",
      "rel_pos shape: torch.Size([1, 30, 30])\n",
      "attn_bias shape: torch.Size([1, 31, 31])\n",
      "heights shape: torch.Size([1, 30])\n",
      "cost_labels shape: torch.Size([1])\n",
      "raw_costs shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes to verify\n",
    "print(f\"x shape: {x_loaded.shape}\")\n",
    "print(f\"rel_pos shape: {rel_pos_loaded.shape}\")\n",
    "print(f\"attn_bias shape: {attn_bias_loaded.shape}\")\n",
    "print(f\"heights shape: {heights_loaded.shape}\")\n",
    "print(f\"cost_labels shape: {cost_labels_loaded.shape}\")\n",
    "print(f\"raw_costs shape: {raw_costs_loaded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST - Loading 2 tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved tensor collection\n",
    "loaded_tensors1 = torch.load(\"./job_queries/tensors/query_1_2024-12-03-20.43.44.200877.pt\")\n",
    "\n",
    "# Access each tensor\n",
    "x_loaded1 = loaded_tensors[\"x\"]\n",
    "rel_pos_loaded1 = loaded_tensors[\"rel_pos\"]\n",
    "attn_bias_loaded1 = loaded_tensors[\"attn_bias\"]\n",
    "heights_loaded1 = loaded_tensors[\"heights\"]\n",
    "cost_labels_loaded1 = loaded_tensors[\"cost_labels\"]\n",
    "raw_costs_loaded1 = loaded_tensors[\"raw_costs\"]\n",
    "\n",
    "# Load the saved tensor collection\n",
    "loaded_tensors2 = torch.load(\"./job_queries/tensors/query_2_2024-12-03-20.43.45.954590.pt\")\n",
    "\n",
    "# Access each tensor\n",
    "x_loaded2 = loaded_tensors[\"x\"]\n",
    "rel_pos_loaded2 = loaded_tensors[\"rel_pos\"]\n",
    "attn_bias_loaded2 = loaded_tensors[\"attn_bias\"]\n",
    "heights_loaded2 = loaded_tensors[\"heights\"]\n",
    "cost_labels_loaded2 = loaded_tensors[\"cost_labels\"]\n",
    "raw_costs_loaded2 = loaded_tensors[\"raw_costs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [x_loaded1, x_loaded2]\n",
    "rel_pos_list = [rel_pos_loaded1, rel_pos_loaded2]\n",
    "attn_bias_list = [attn_bias_loaded1, attn_bias_loaded2]\n",
    "heights_list = [heights_loaded1, heights_loaded2]\n",
    "cost_labels_list = [cost_labels_loaded1, cost_labels_loaded2]\n",
    "raw_costs_list = [raw_costs_loaded1, raw_costs_loaded2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 2\n",
      "First sample: ({'x': tensor([[[1., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [2., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [3., 1., 0.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 'attn_bias': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf]]]), 'rel_pos': tensor([[[ 1,  2,  3,  4,  4,  5,  5,  6,  6,  7,  8,  8,  9, 10, 10, 11, 11,\n",
      "           9,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61,  1,  2,  3,  3,  4,  4,  5,  5,  6,  7,  7,  8,  9,  9, 10, 10,\n",
      "           8,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61,  1,  2,  2,  3,  3,  4,  4,  5,  6,  6,  7,  8,  8,  9,  9,\n",
      "           7,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61,  1, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61,  1,  2,  2,  3,  3,  4,  5,  5,  6,  7,  7,  8,  8,\n",
      "           6,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61,  1, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61,  1,  2,  2,  3,  4,  4,  5,  6,  6,  7,  7,\n",
      "           5,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61,  1, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  3,  3,  4,  5,  5,  6,  6,\n",
      "           4,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  2,  3,  4,  4,  5,  5,\n",
      "           3, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1, 61, 61, 61, 61, 61, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  3,  3,  4,  4,\n",
      "           2, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  2,  3,  3,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1, 61, 61, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  2,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "           1, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "          61,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]]), 'heights': tensor([[12, 11, 10,  2,  9,  2,  8,  2,  7,  6,  2,  2,  5,  4,  2,  2,  3,  2,\n",
      "          2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])}, (tensor([0.9965], dtype=torch.float64), tensor([66844.], dtype=torch.float64)))\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset\n",
    "dataset = PlanTreeDataset(\n",
    "    2,\n",
    "    x_list,\n",
    "    attn_bias_list,\n",
    "    rel_pos_list,\n",
    "    heights_list,\n",
    "    cost_labels_list,\n",
    "    raw_costs_list\n",
    ")\n",
    "\n",
    "print(\"Dataset length:\", len(dataset))\n",
    "print(\"First sample:\", dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 2\n",
      "First sample: ({'x': tensor([[[1., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [2., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [3., 1., 0.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 'attn_bias': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "          -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf]]]), 'rel_pos': tensor([[[ 1,  2,  3,  4,  4,  5,  5,  6,  6,  7,  8,  8,  9, 10, 10, 11, 11,\n",
      "           9,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61,  1,  2,  3,  3,  4,  4,  5,  5,  6,  7,  7,  8,  9,  9, 10, 10,\n",
      "           8,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61,  1,  2,  2,  3,  3,  4,  4,  5,  6,  6,  7,  8,  8,  9,  9,\n",
      "           7,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61,  1, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61,  1,  2,  2,  3,  3,  4,  5,  5,  6,  7,  7,  8,  8,\n",
      "           6,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61,  1, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61,  1,  2,  2,  3,  4,  4,  5,  6,  6,  7,  7,\n",
      "           5,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61,  1, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  3,  3,  4,  5,  5,  6,  6,\n",
      "           4,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  2,  3,  4,  4,  5,  5,\n",
      "           3, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1, 61, 61, 61, 61, 61, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  3,  3,  4,  4,\n",
      "           2, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  2,  3,  3,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1, 61, 61, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,  2,  2,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1, 61,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  1,\n",
      "          61, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "           1, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "          61,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]]), 'heights': tensor([[12, 11, 10,  2,  9,  2,  8,  2,  7,  6,  2,  2,  5,  4,  2,  2,  3,  2,\n",
      "          2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])}, (tensor([0.9965], dtype=torch.float64), tensor([66844.], dtype=torch.float64)))\n"
     ]
    }
   ],
   "source": [
    "num_copies = 2\n",
    "\n",
    "# Replicate data\n",
    "replicated_x = [x_loaded.clone() for _ in range(num_copies)]\n",
    "replicated_attn_bias = [attn_bias_loaded.clone() for _ in range(num_copies)]\n",
    "replicated_rel_pos = [rel_pos_loaded.clone() for _ in range(num_copies)]\n",
    "replicated_heights = [heights_loaded.clone() for _ in range(num_copies)]\n",
    "replicated_cost_labels = [cost_labels_loaded.clone() for _ in range(num_copies)]  # Tensor replicated\n",
    "replicated_raw_costs = [raw_costs_loaded.clone() for _ in range(num_copies)]  # List replicated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize dataset\n",
    "dataset = PlanTreeDataset(\n",
    "    num_copies,\n",
    "    replicated_x,\n",
    "    replicated_attn_bias,\n",
    "    replicated_rel_pos,\n",
    "    replicated_heights,\n",
    "    replicated_cost_labels,\n",
    "    replicated_raw_costs\n",
    ")\n",
    "\n",
    "print(\"Dataset length:\", len(dataset))\n",
    "print(\"First sample:\", dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(replicated_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(replicated_x) == num_copies\n",
    "assert len(replicated_attn_bias) == num_copies\n",
    "assert len(replicated_rel_pos) == num_copies\n",
    "assert len(replicated_heights) == num_copies\n",
    "assert len(replicated_cost_labels) == num_copies\n",
    "assert len(replicated_raw_costs) == num_copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PlanTreeDataset with optional costs\n",
    "#dataset = PlanTreeDataset(1, [x], [attn_bias], [rel_pos], [heights], cost_labels, raw_costs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 2\n",
      "Sample contents:\n",
      "Feature Matrix (x): torch.Size([1, 30, 1161])\n",
      "Attention Bias (attn_bias): torch.Size([1, 31, 31])\n",
      "Relative Positions (rel_pos): torch.Size([1, 30, 30])\n",
      "Heights (heights): torch.Size([1, 30])\n",
      "Label: (tensor([0.9965], dtype=torch.float64), tensor([66844.], dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the dataset\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# Access a single sample\n",
    "sample, label = dataset[0]\n",
    "\n",
    "# Print the sample contents\n",
    "print(\"Sample contents:\")\n",
    "print(\"Feature Matrix (x):\", sample['x'].shape)\n",
    "print(\"Attention Bias (attn_bias):\", sample['attn_bias'].shape)\n",
    "print(\"Relative Positions (rel_pos):\", sample['rel_pos'].shape)\n",
    "print(\"Heights (heights):\", sample['heights'].shape)\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/db2inst1/learnedwmp/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Avg Loss: 7.255745373413447e-06, Time: 1.5563831329345703\n",
      "Median: 1.0066066600943233\n",
      "Mean: 1.0066066600943233\n",
      "Epoch: 20  Avg Loss: 1.1941439879592508e-05, Time: 24.219303846359253\n",
      "Median: 1.0099321741667164\n",
      "Mean: 1.0099321741667164\n",
      "Epoch: 40  Avg Loss: 1.1941439879592508e-05, Time: 46.253968238830566\n",
      "Median: 1.0099321741667164\n",
      "Mean: 1.0099321741667164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/db2inst1/learnedwmp/templates/job-templatizing-queryformer-modified/model/trainer.py:42: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(np.log(ps), np.log(ls))\n",
      "/home/db2inst1/learnedwmp/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/db2inst1/learnedwmp/templates/job-templatizing-queryformer-modified/model/trainer.py:42: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(np.log(ps), np.log(ls))\n"
     ]
    }
   ],
   "source": [
    "# Example numpy label\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "\n",
    "from model import trainer\n",
    "importlib.reload(trainer)\n",
    "from  model.trainer import train_single, train\n",
    "\n",
    "\n",
    "crit = nn.MSELoss()\n",
    "\n",
    "# Train the model with the numpy label\n",
    "# trained_model = train_single(model, dataset, dataset, crit, cost_norm, args)\n",
    "model, best_model_path, train_embeddings, val_embeddings = train(model, dataset, dataset, crit, cost_norm, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training embeddings (best epoch): 2\n",
      "First training embedding shape: (1417,)\n",
      "Number of validation embeddings (best epoch): 2\n",
      "First validation embedding shape: (1417,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training embeddings (best epoch): {len(train_embeddings)}\")\n",
    "print(f\"First training embedding shape: {train_embeddings[0].shape}\")\n",
    "print(f\"Number of validation embeddings (best epoch): {len(val_embeddings)}\")\n",
    "print(f\"First validation embedding shape: {val_embeddings[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First validation embedding shape: [ 38.056725  -7.931094 -32.452435 ...  14.457197 -36.5028   -15.373121]\n"
     ]
    }
   ],
   "source": [
    "print(f\"First validation embedding shape: {val_embeddings[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First validation embedding shape: [ 38.056725  -7.931094 -32.452435 ...  14.457197 -36.5028   -15.373121]\n"
     ]
    }
   ],
   "source": [
    "print(f\"First validation embedding shape: {val_embeddings[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1417"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Embedding 0:\n",
      "[ 3.80567245e+01 -7.93109417e+00 -3.24524345e+01 -3.06410146e+00  7.42445707e+00 -2.85364094e+01  3.80522656e+00 -9.39973450e+00 -9.93508625e+00  6.81154728e+00  1.66052418e+01  7.26188183e+00 -2.70576954e+01  2.34494257e+00  2.55129070e+01 -3.47973938e+01  1.42232962e+01 -2.23608704e+01  1.97827458e-01 -1.18208809e+01  3.17893448e+01  2.61219978e-01  5.16502151e+01 -5.22635803e+01 -4.26811409e+01  2.68874569e+01  4.92067766e+00 -2.36941948e+01 -8.56904697e+00  1.12485065e+01  3.68134460e+01 -6.20116119e+01 -2.85249500e+01  7.14427292e-01  2.10071220e+01  9.74221230e+00 -1.87018204e+01 -1.93583069e+01 -1.86332417e+00 -7.93417120e+00  2.67011185e+01 -6.43783855e+00  1.88519840e+01  1.69657183e+00  5.80380154e+00 -4.65860176e+01 -1.02494307e+01 -2.70782337e+01  1.91007919e+01 -3.13161731e+00  2.57109528e+01  1.98058434e+01  6.66168690e+00  2.76375885e+01  4.00322609e+01 -8.97790623e+00  5.38343859e+00  2.97897549e+01 -4.02928658e+01 -7.92449045e+00 -3.05904541e+01 -8.06316566e+00\n",
      " -3.45649643e+01  2.86995621e+01 -7.36907148e+00  4.06677551e+01  4.74881058e+01 -1.76662040e+00 -3.08766518e+01  4.38862038e+00 -1.77325363e+01 -1.23690615e+01  1.40083294e+01 -2.44414635e+01 -5.62289000e+00  5.03398705e+01  2.56060934e+00  2.49338055e+01 -5.53456163e+00 -1.41631489e+01  5.69747658e+01  9.14788532e+00 -2.93851209e+00 -4.69124680e+01 -9.97335529e+00 -2.89406185e+01  2.15360379e+00 -3.41502075e+01  1.08476524e+01  4.72912490e-01 -1.33676195e+00  2.28575840e+01  4.90871582e+01  1.83465366e+01  5.76879072e+00  2.66225452e+01  2.84749241e+01  7.42191696e+00 -3.16351032e+00  4.79302940e+01 -4.78585386e+00  1.17685223e+00  3.49208260e+01  1.58069551e+00 -3.12167168e+01 -1.70501442e+01  4.00876350e+01 -1.65542698e+01  3.62584801e+01  1.61083813e+01  2.13161907e+01  1.45294542e+01 -1.58440542e+01 -3.06663265e+01  3.05716801e+01  3.69260788e+01  1.40094709e+01 -7.55298805e+00 -1.20033321e+01 -3.24035416e+01 -1.00291920e+01  3.70846443e+01 -7.83420086e+00  1.38661118e+01\n",
      " -3.51155548e+01 -2.33490047e+01 -1.34224319e+01 -2.79565735e+01  1.57743130e+01  4.24823227e+01  1.19368649e+01  1.49138784e+01 -4.04502583e+00  8.80660820e+00  2.24382362e+01 -4.82983475e+01 -2.01919975e+01 -9.27560520e+00  2.40657921e+01  7.61244011e+00  2.02380886e+01 -2.40430698e+01 -1.15888023e+01  1.14485588e+01 -1.74312725e+01  8.94542789e+00 -1.86126366e+01  2.87387981e+01 -7.21624947e+00 -2.91066589e+01 -3.31376028e+00  2.77767735e+01  2.93994484e+01  4.24202766e+01 -1.17833300e+01 -7.93920088e+00  3.14487648e+01  1.31909161e+01  3.12916679e+01  4.33967934e+01  2.86123810e+01  3.10279255e+01  8.66948795e+00 -1.04081182e+01 -4.25973930e+01 -1.51734324e+01 -1.98673267e+01  3.70243835e+01  1.83432388e+01  1.73806477e+01  2.79865913e+01 -3.01877174e+01 -3.61885262e+01 -3.98217964e+01 -1.69930019e+01 -5.02743683e+01  1.35603371e+01  1.14967527e+01  5.02239761e+01 -2.21561699e+01  1.04659986e+01  7.57612944e+00 -1.80978756e+01 -3.21456623e+00  2.32561951e+01  5.92749786e+01\n",
      "  1.96314964e+01  2.42998447e+01 -1.35586643e+01 -2.43938847e+01 -2.96875038e+01 -4.03191376e+01  4.37917747e+01  3.34637871e+01  2.55411587e+01  2.43292942e+01  1.39097795e+01  7.95084667e+00  1.11429214e-01  4.69647141e+01 -2.60620708e+01  3.55435181e+01  1.80642433e+01 -4.20965500e+01 -3.95471153e+01 -1.54284105e+01 -1.70703278e+01  2.95064411e+01  2.44545593e+01  3.61747055e+01 -4.17454147e+01 -2.12702579e+01  2.15713501e+01  3.27035446e+01 -3.62266693e+01 -2.29280910e+01  2.56637325e+01 -2.38807850e+01  3.79926834e+01 -7.52088737e+00  9.79691982e+00 -2.63632202e+01  1.44265900e+01 -1.96385479e+01 -2.32269821e+01 -1.55509167e+01  2.59634953e+01 -3.61304398e+01  2.85754395e+01  1.77552547e+01 -2.11991482e+01  1.32333565e+01 -2.71933193e+01 -6.58139229e+00  3.77128124e+00  1.30419779e+01  3.98628349e+01  1.25176477e+01 -4.05524750e+01  1.61073720e+00 -4.23830299e+01 -3.49332123e+01 -3.67579956e+01  8.65074825e+00  2.53504467e+01  2.70170937e+01 -7.66678381e+00 -3.31178627e+01\n",
      "  4.71609764e+01  1.07051790e+00  3.59730759e+01  1.27612686e+01 -2.44306889e+01 -2.97515163e+01  9.96364021e+00 -2.12455058e+00  1.59429300e+00  3.84464417e+01 -1.07834949e+01  3.75694351e+01  1.08707790e+01 -3.58622322e+01  2.08642044e+01  3.65083504e+01  3.69623137e+00  4.88483620e+00  2.80860500e+01  2.13830090e+01 -4.22696114e+01 -1.00375147e+01 -4.66781759e+00  1.92236042e+01 -1.30896406e+01  5.04928923e+00 -1.29103308e+01 -2.92500877e+01  5.50048599e+01 -1.31752090e+01  1.07476988e+01  4.07990646e+00 -5.82928276e+00 -2.03140640e+01 -1.63465595e+01  2.65174980e+01 -6.49604130e+00  1.06367040e+00 -4.31904869e+01 -2.51341076e+01  9.10523796e+00 -2.95786591e+01 -9.70576668e+00  2.34339275e+01 -8.89089775e+00 -2.37014370e+01  4.78759270e+01  1.24930344e+01 -5.92377520e+00  3.02460432e+00 -1.67646942e+01 -3.08714066e+01 -1.88048115e+01 -2.28198195e+00  5.64311171e+00 -7.21302319e+00 -9.51603889e-01 -3.14358006e+01  3.37811584e+01  9.93672943e+00 -3.69790154e+01  1.70884628e+01\n",
      "  2.05069904e+01 -2.66274948e+01  4.46201401e+01 -1.92478390e+01 -1.76493626e+01 -2.07570972e+01 -5.32011032e+00 -5.02107925e+01  2.10721836e+01 -2.65123520e+01  2.36076393e+01 -6.11200428e+00 -7.36365891e+00 -2.23507690e+01  3.13122768e+01 -1.75675030e+01 -6.39912891e+00  1.54730282e+01 -3.58802795e+01  4.39269352e+00  2.12019901e+01 -5.50725269e+00 -4.24738235e+01  2.21926193e+01 -4.91131353e+00 -1.16362143e+01  1.64764614e+01  3.09964418e-01 -3.32199645e+00  3.62105331e+01  4.37723694e+01  2.81787663e+01 -4.79380655e+00 -4.08718452e+01  1.50603848e+01  6.66000938e+00 -3.07948933e+01  3.26563120e+00  3.01163216e+01 -4.51877356e+00  4.43441772e+01  1.34801493e+01 -1.95137482e+01 -2.71098423e+01  5.53567314e+01 -3.15024052e+01  2.44737625e+01  8.64348698e+00 -3.02802677e+01  2.99593139e+00 -2.23944664e+00 -3.21068573e+01 -2.97717037e+01 -2.29301167e+01  4.85995626e+00  3.85420265e+01 -2.87470760e+01  4.97501907e+01 -1.83255386e+00  3.22547112e+01 -4.45145845e-01  1.27787933e+01\n",
      "  8.01180553e+00  3.36323662e+01 -1.07370052e+01 -2.12646656e+01 -3.27437706e+01 -3.15612965e+01  1.92622890e+01 -1.64577751e+01 -2.13382778e+01  5.86698265e+01  3.35477142e+01  3.70062370e+01  1.91365528e+00 -4.01584015e+01 -2.52624149e+01 -3.91244087e+01 -3.70477180e+01 -1.75012817e+01  4.16142159e+01  3.24338188e+01  2.58192501e+01  7.16738319e+00  1.21280594e+01  7.32269430e+00  1.68952141e+01  1.62460766e+01 -2.40016670e+01  3.30928955e+01  4.20295563e+01 -5.46637573e+01 -7.75574589e+00  2.08026390e+01 -3.53766479e+01 -1.33797798e+01 -2.14540730e+01  2.14543648e+01 -1.85749397e+01  9.43865061e-01  2.23657894e+01 -2.20650139e+01 -1.24814167e+01 -2.63918037e+01 -2.88546038e+00 -3.02376232e+01  1.73913326e+01  3.48584533e+00  2.93966942e+01  3.02342091e+01 -2.54632664e+01 -2.00515862e+01 -2.59839249e+01  4.36979866e+00  1.04643621e+01 -1.01354952e+01  3.96490364e+01  5.11235313e+01  4.81655083e+01 -3.13456178e+00  3.07310772e+01  2.23041744e+01  4.11567268e+01  3.84245949e+01\n",
      "  4.98352814e+01  1.93156281e+01  1.30873013e+01  2.92206497e+01 -1.02572107e+01  2.18883934e+01  3.13176804e+01  2.06276112e+01  1.11507959e+01  2.46593933e+01 -2.27470226e+01 -3.00182891e+00 -3.16117525e+00 -1.81215343e+01  3.51515465e+01  3.50793228e+01 -1.09902554e+01  3.82872734e+01  3.10679054e+01  1.06569309e+01 -5.59621735e+01  2.51801414e+01  1.85833931e+01 -3.72812691e+01  2.41390209e+01 -2.49763107e+01 -2.16682577e+00 -2.93966222e+00 -2.20466175e+01  3.61755104e+01  3.07056580e+01  2.62283077e+01  1.07293739e+01 -8.25617218e+00 -1.24093342e+01  3.67031212e+01 -1.00605907e+01  1.40673780e+01 -2.84293938e+01  3.56304207e+01 -2.09615231e-01 -3.03248386e+01 -4.30971489e+01  3.35303926e+00  3.81847153e+01  2.09652557e+01 -4.89085732e+01  2.39046803e+01 -2.81795616e+01  1.46281462e+01  1.92661076e+01 -1.79809208e+01 -1.97893982e+01 -1.92387176e+00 -1.19478245e+01  2.65673447e+00  1.38262463e+01  3.38443184e+00  2.73827438e+01 -4.01356812e+01  1.81123257e+01 -7.79913855e+00\n",
      "  2.76978645e+01  4.53832512e+01  1.93982792e+01  1.22391195e+01 -1.00149784e+01  1.86908646e+01 -9.94881821e+00  2.49745331e+01  7.82203770e+00  2.11756878e+01 -4.24957123e+01 -2.87816000e+00  8.39968967e+00  5.04288626e+00  2.63286819e+01  1.25717802e+01  8.41851997e+00  4.48913956e+01  1.22866898e+01  2.48625546e+01 -2.96073475e+01 -1.16894417e+01 -8.90994072e-02  5.58821297e+00  3.43081398e+01  2.33184052e+01  9.65304947e+00 -3.15505958e+00 -3.25473137e+01  7.10311556e+00  2.47372131e+01  3.85082550e+01 -3.75318947e+01 -1.84277878e+01  3.01649818e+01  4.30193663e+00  3.34095230e+01  3.22628670e+01 -2.54447765e+01  4.11004066e+01  5.13920097e+01  4.44336548e+01 -3.29052505e+01  1.04017754e+01  2.05279293e+01 -1.45304680e+00 -1.76981030e+01 -4.66584444e+00  2.95870056e+01  1.52671986e+01 -2.41168385e+01 -2.79526958e+01  2.50961552e+01  1.79076805e+01 -2.53502893e+00 -8.22692490e+00 -1.27683210e+01  4.11484108e+01  3.83759956e+01 -3.64709320e+01 -2.20606918e+01  3.21570129e+01\n",
      "  3.29646225e+01  1.74199677e+01 -1.72882442e+01 -3.34946976e+01 -1.34765081e+01 -3.92118607e+01 -4.10614738e+01  2.13891544e+01 -3.02858448e+00  3.25854301e+01 -1.03120432e+01 -7.97699070e+00 -5.32973623e+00  4.10868645e+01  5.22173271e+01 -7.09412432e+00  2.31170292e+01 -5.43284378e+01  3.24462128e+01 -4.15615311e+01  1.24905548e+01 -2.56760616e+01 -2.69089699e+01 -7.02471876e+00 -3.89774094e+01 -2.75956383e+01 -3.05956707e+01 -4.26084328e+01 -3.33005676e+01 -6.53040695e+00 -2.35065212e+01  3.78837204e+01  3.41887131e+01 -2.14563637e+01  4.99180641e+01 -4.70972023e+01  6.60202885e+00  1.45839367e+01 -5.20314255e+01 -5.15179634e+00  3.89413834e+01 -2.07709026e+01 -3.32225075e+01 -2.49918556e+01 -3.74655800e+01 -1.30793409e+01  3.03606262e+01  5.15485535e+01  1.72341137e+01 -5.75010109e+00  3.36066551e+01 -3.09701753e+00 -1.78222656e+01 -3.95253983e+01 -7.39464569e+00 -1.17949123e+01 -5.43425035e+00  3.79180107e+01  1.14818840e+01 -3.01355705e+01  3.58984146e+01 -1.63457489e+01\n",
      "  1.88411546e+00 -2.06699257e+01 -1.58807182e+01  1.63418331e+01 -1.36801186e+01  4.07019186e+00 -9.58816719e+00 -2.36905079e+01  1.35643082e+01 -1.69702969e+01  2.27431469e+01 -4.25429382e+01  1.25293713e+01 -8.06975365e+00 -2.86397686e+01 -5.32176704e+01 -1.87363892e+01 -8.21071148e+00 -4.31938553e+01 -4.51571846e+00  2.24886856e+01 -2.91038456e+01  1.62965584e+01 -1.84064331e+01  5.40589218e+01  8.48601151e+00  7.45214272e+00 -3.91155586e+01 -1.58117857e+01 -1.72684917e+01  3.88174858e+01  3.85878258e+01 -1.82448387e+01  3.88516197e+01 -3.26490517e+01 -3.14900398e+01  3.69526978e+01  2.70923653e+01  1.33990850e+01 -2.90993959e-01  2.44005604e+01  3.95226898e+01  4.22583122e+01  3.43700027e+01 -3.78259506e+01  1.93200245e+01 -2.37215195e+01  1.36456318e+01  1.09922438e+01  1.49042110e+01  2.54852982e+01  1.40750380e+01  2.60609913e+01  2.66740837e+01  5.09944191e+01 -3.50834694e+01  2.18651414e-01  1.23067369e+01  9.71116734e+00 -1.83481598e+01 -1.35157290e+01 -1.55951464e+00\n",
      "  1.10663891e+00 -2.03158627e+01 -1.46669712e+01 -3.99823074e+01  5.91701603e+00 -9.65619087e+00  9.97198582e-01 -3.56041574e+00 -2.29164543e+01  3.01975880e+01 -1.20907183e+01 -4.09393311e-02 -3.87969933e+01 -5.29853702e-01 -7.06188965e+00  3.72419624e+01 -6.31727791e+00 -5.20502234e+00 -1.02760353e+01 -1.58668928e+01 -4.57183990e+01 -4.31157074e+01 -3.35445023e+01  9.89628220e+00 -2.68732033e+01 -3.44693680e+01  5.66518259e+00  1.59857988e+01 -1.68965912e+01  1.19330931e+01 -3.51726952e+01  3.39956856e+01  1.64865494e+01 -3.96550941e+01  1.44768877e+01  2.88272934e+01 -1.22302790e+01 -5.28895855e+00 -2.08378468e+01 -5.32843704e+01 -1.72085304e+01 -8.52765560e+00  4.96376228e+00 -1.17613792e+01  1.13802757e+01  4.28004265e-01 -2.89435005e+01  2.47322292e+01  6.02104092e+00 -1.79432812e+01  2.25905895e+01 -9.89037132e+00 -4.24249649e+00  9.49442673e+00  1.13161821e+01  1.87718353e+01  6.73059464e+00 -2.75166149e+01 -4.14306221e+01  1.91282511e+00 -1.01141281e+01 -1.54194584e+01\n",
      " -1.44009743e+01 -4.21543579e+01  2.48991680e+01  4.14164658e+01  2.21402416e+01 -2.05936890e+01 -9.41682243e+00 -1.03059092e+01 -1.35643826e+01 -1.79984798e+01 -2.19930763e+01 -1.43042669e+01  2.53860130e+01 -2.52167225e+01 -1.60728588e+01 -2.95021462e+00 -2.78986549e+01 -1.36644650e+01 -1.21462326e+01  4.27914581e+01 -3.05539246e+01 -1.46991377e+01  4.25650368e+01 -3.32389412e+01  3.19323463e+01  4.25974884e+01 -2.75559006e+01  2.58001995e+01  1.44017277e+01 -1.96651192e+01 -9.29542828e+00 -6.81739521e+00 -2.16675892e+01  4.46217346e+00  3.96451187e+01  8.95230007e+00  3.43985748e+01  2.02086163e+01 -3.38044000e+00 -1.74409962e+01  3.36524887e+01 -3.13671207e+01  2.45314903e+01 -4.10226250e+01  6.51740170e+00  1.00031710e+01 -1.06555214e+01 -2.28230171e+01  4.28300819e+01 -1.71473522e+01 -1.33728132e+01  2.47053185e+01 -3.14947739e+01 -1.11705055e+01 -5.09025650e+01 -1.02745457e+01 -1.64562855e+01 -2.87426434e+01  1.20935621e+01 -9.14018250e+00  7.23664379e+00 -3.70822296e+01\n",
      " -2.27807255e+01  1.93701439e+01 -5.84195566e+00 -3.81181183e+01  2.63651276e+01 -5.01503639e+01  3.39292717e+00 -2.50699735e+00  3.75997849e+01 -1.10374475e+00 -7.79306412e+00 -7.42287636e-02  1.75401402e+01  1.04725242e-01 -1.90102940e+01  8.97533512e+00  2.25065002e+01  5.29889774e+00 -1.60347443e+01 -1.24727859e+01 -4.35584450e+01  8.73443317e+00  1.44418545e+01 -8.04575825e+00  1.03908072e+01 -3.34308090e+01  1.83827229e+01  4.09237251e+01 -2.90456295e+00 -1.49816628e+01  1.48055973e+01 -1.38679667e+01 -1.44342337e+01 -3.91528854e+01  2.46452599e+01 -6.85463810e+00  3.48850656e+00 -4.35759211e+00  1.54066992e+01  9.34141254e+00 -1.98009663e+01  2.30928993e+00 -6.66488552e+00 -5.77788687e+00  2.13902130e+01  9.80003166e+00 -3.54613876e+01 -8.71295738e+00 -6.43878937e-01  1.90992203e+01 -2.21447716e+01  3.24102592e+01  2.75748177e+01  2.59709530e+01 -2.31224213e+01 -2.56294804e+01 -3.83935699e+01 -8.13549328e+00 -2.09624233e+01  1.51606627e+01 -5.53928995e+00  1.37531891e+01\n",
      " -4.64028263e+00 -2.84177990e+01  1.84718075e+01  2.02322555e+00 -2.82864914e+01 -3.57775116e+01  1.45751944e+01 -3.47757530e+01 -3.85295677e+01  2.51453304e+00 -6.06546736e+00  1.99923935e+01  5.03610802e+01  2.87959442e+01  5.03976326e+01  3.48447838e+01  3.97082481e+01 -3.02808037e+01  4.42508888e+01  8.68386173e+00 -1.53355684e+01 -5.52591610e+00 -4.17735367e+01  3.36165924e+01 -3.40863571e+01 -4.61654997e+00 -1.93543301e+01  3.11187038e+01  1.46196280e+01 -1.92555466e+01  3.84777045e+00 -7.40588188e+00 -2.01511040e+01 -2.84728527e+00  3.50982170e+01  8.33352566e-01 -1.10630207e+01 -2.81839681e+00  4.30927753e+00 -8.20040226e+00  3.29427757e+01  3.53239555e+01  1.40452766e+00  5.44136467e+01 -3.40622826e+01 -1.56171818e+01  1.93400898e+01 -1.32939281e+01  5.11166191e+01  2.97300949e+01  2.98030663e+01 -1.55089808e+01 -2.23985653e+01 -4.36345291e+00 -3.34901428e+01 -4.24484482e+01  3.39827576e+01 -2.52102947e+01 -3.77674484e+01  2.33714128e+00 -3.22022591e+01 -3.37918854e+01\n",
      " -2.63144417e+01 -2.48856297e+01  3.29836044e+01  8.83729517e-01 -3.42432098e+01  2.76552620e+01 -1.59129448e+01  2.45235767e+01 -1.02571497e+01 -9.09160709e+00  2.12615204e+01  8.54707432e+00  8.19224453e+00  2.55580196e+01 -4.60615587e+00  7.44991684e+00 -6.53848267e+00 -2.50402374e+01 -4.25480499e+01 -4.15713263e+00 -6.58800840e-01 -1.40681496e+01  2.25557709e+01 -1.58676968e+01 -2.29577160e+01 -2.10700378e+01  8.19607735e+00  2.36247969e+00  2.43541832e+01 -2.56828403e+00  1.16457996e+01 -1.89963894e+01  1.81407089e+01 -3.25620842e+01  1.51191025e+01  1.44168139e+01  3.48660736e+01 -2.37873688e+01 -1.39842091e+01  4.96658096e+01  3.19261913e+01  8.18212605e+00 -3.10137291e+01  9.62218475e+00  3.44412537e+01 -1.97873211e+01 -4.73718185e+01 -3.19731407e+01  2.43028679e+01  1.08217506e+01  1.23128023e+01 -9.81692123e+00 -3.11831284e+01  7.71003771e+00  1.25703592e+01  3.35472703e-01 -1.27796888e-01  1.86852055e+01  1.87736588e+01  1.81340466e+01 -3.37991180e+01  1.90893345e+01\n",
      "  1.72783508e+01 -1.17607460e+01 -1.05310087e+01 -4.04341660e+01  2.16313591e+01  1.04712486e+01 -2.80265388e+01  2.94177361e+01 -1.19773436e+01  3.57446213e+01 -9.23466492e+00  1.05684071e+01 -1.55655727e+01 -1.22797146e+01 -4.61203613e+01  4.08371849e+01 -1.67039356e+01  3.09591923e+01 -7.06901550e-01 -2.82742920e+01  3.15447545e+00 -1.52405577e+01 -2.09190788e+01  4.08026123e+01 -2.28289642e+01  2.15951371e+00 -2.67778950e+01  3.26308403e+01 -4.01939888e+01 -1.50885487e+01 -3.67412138e+00  6.42055988e-01 -3.80351782e+00  1.38686094e+01  1.21997957e+01 -4.96732235e+00 -1.00105209e+01  5.42136002e+00 -5.25603981e+01 -4.95043144e+01  1.58874273e-01  4.59583044e+00 -8.18703270e+00  2.45090389e+00 -1.07539692e+01  1.44721098e+01 -1.41525805e+00  5.28955154e+01  4.71234512e+00  2.29167137e+01  3.46162148e+01 -6.15068207e+01 -3.12352371e+01 -3.56945992e+01 -7.82990456e+00  2.34578018e+01  1.21661797e+01 -1.58950639e+00  1.58101635e+01  2.58430988e-01 -7.18654156e+00  5.08899345e+01\n",
      " -2.02657509e+01 -2.54621029e+01 -4.91070595e+01 -4.55595398e+01 -1.42844810e+01  3.40547371e+01  2.88958502e+00 -8.42211723e+00  1.57736750e+01 -6.60861664e+01 -1.68063374e+01 -1.31546555e+01  2.87918987e+01 -2.80257263e+01 -2.95838871e+01  3.20068474e+01 -1.32405090e+01  1.68216777e+00 -8.45486069e+00  3.52383614e+01 -3.22103262e+00  1.41240997e+01  3.78398514e+01  3.96447563e+01  3.26308870e+00 -2.58893318e+01  5.93280649e+00 -1.11842299e+01  2.79990044e+01 -8.77616024e+00  4.14201622e+01  1.34152403e+01 -7.74781847e+00 -7.59489179e-01  1.15127335e+01 -2.01887455e+01 -5.43920517e+01 -2.97525272e+01  3.16834431e+01  1.77462780e+00  1.28163366e+01  2.55720139e+00  3.38170357e+01 -3.82304688e+01 -3.51032677e+01 -6.79957724e+00 -4.28905296e+01 -2.61848793e+01  1.28616152e+01  2.85832157e+01 -2.90863342e+01 -1.05254774e+01 -9.91198063e-01 -4.23770218e+01  5.08706665e+00  3.19087181e+01  1.52461405e+01 -3.10860996e+01 -1.11494684e+01 -2.47135830e+01  3.55176659e+01  7.69848251e+00\n",
      " -4.38424606e+01 -1.32667217e+01 -2.74037123e-01 -3.74196167e+01 -3.26249466e+01  2.03577118e+01 -2.37119236e+01  6.41582918e+00  4.10016489e+00 -3.28563805e+01  3.77325974e+01 -3.52804494e+00 -1.99805412e+01 -8.01656151e+00 -1.54161053e+01 -1.78951550e+01  5.42891350e+01  7.59982681e+00  2.06884098e+01 -3.90078354e+01  3.23506927e+01  6.39490461e+00 -2.18485909e+01 -1.99230742e+00  1.97089119e+01  1.88821125e+01 -1.02514057e+01  3.24398499e+01 -8.35340214e+00 -6.05379257e+01 -1.75662079e+01 -9.44964123e+00 -1.44794836e+01  1.50016460e+01 -2.01816654e+01 -4.05790758e+00 -1.78632355e+01 -2.43012104e+01 -2.76177254e+01  3.82497787e-01 -2.27606792e+01  1.30368538e+01 -5.06912470e+00 -1.45735645e+01 -2.51398277e+00 -6.17612648e+00 -2.80292816e+01  2.59090862e+01  1.85516415e+01  3.83386993e+00 -4.88969078e+01  3.07558861e+01 -3.20478439e+00 -1.60937843e+01  1.60177517e+01 -3.35527277e+00  4.04797935e+01 -1.38445024e+01  3.47331963e+01  3.15514183e+01 -3.35358963e+01  3.85605011e+01\n",
      "  1.95292130e+01 -9.48446465e+00  3.92034798e+01 -1.19113731e+01  1.06940498e+01 -4.36615829e+01 -3.98714867e+01 -5.91292858e+00 -2.71784782e+01  3.65047646e+00  1.73726196e+01  1.62615490e+01 -3.78975525e+01 -3.64324875e+01  6.99028969e-01 -2.31291056e+00 -3.43607712e+01  3.89311714e+01 -3.38795242e+01 -1.39107237e+01 -3.33073139e+00 -3.70091782e+01 -9.40838814e+00  4.37260666e+01  1.75705261e+01 -3.42798462e+01  1.98831635e+01  6.18062878e+00 -2.19372025e+01  1.61506538e+01  1.76143665e+01  1.09443760e+01 -3.33256035e+01  1.10013008e+01 -2.42185898e+01  2.11518478e+01 -6.02029324e+00  1.88999214e+01 -7.58560276e+00  4.53259087e+01  9.84319878e+00 -2.23814225e+00 -2.13273735e+01 -6.58340645e+00  8.40041542e+00 -1.93693962e+01  2.54310951e+01  1.30097413e+00  2.90643005e+01  1.78370273e+00  3.74297523e+01  2.24217415e+01 -3.76359291e+01 -2.22110558e+00 -5.15549736e+01 -3.97166672e+01  9.77345848e+00  1.90739632e+01 -4.49942627e+01  2.58825474e+01 -7.23001480e+00  5.95870094e+01\n",
      " -4.67402077e+00 -3.13066244e+00  9.11880875e+00  2.91732044e+01  4.27184105e-02  2.00596409e+01  2.55041599e+00 -8.74982357e+00 -2.09276009e+01  1.63444500e+01  1.50133533e+01  1.07181621e+00  1.23832283e+01  1.40424976e+01 -3.50921974e+01 -4.36914024e+01  1.59839382e+01 -2.59204078e+00  3.25034256e+01  6.54986858e+00 -1.35023527e+01 -2.21567478e+01  3.05871181e+01  1.77488461e+01  1.34262190e+01 -1.62602425e+01  4.87931290e+01  4.20933952e+01 -3.78183675e+00  2.49077053e+01 -1.38822651e+01  1.74478569e+01  3.16521320e+01 -8.03070164e+00 -3.24426117e+01  1.32714157e+01  1.66003513e+01 -1.50286674e+01  1.98773537e+01 -4.26296854e+00 -3.00511532e+01 -2.89529972e+01 -2.29549007e+01  1.94868279e+01 -3.61336350e+00 -1.65626240e+01  6.17327642e+00 -1.54304540e+00  3.15755959e+01  5.89354181e+00  3.56856003e+01  1.60361791e+00  7.13365173e+00 -1.84810781e+00  5.04815245e+00 -2.89859314e+01  5.71370468e+01  4.90654602e+01 -2.83923893e+01 -9.89497280e+00  1.13867054e+01  2.42384205e+01\n",
      "  3.60958710e+01  4.70556412e+01  1.49942236e+01 -6.27021599e+00  1.29535818e+01 -1.93573570e+01  6.01516724e+01  8.38474464e+00 -1.23440657e+01 -2.69282627e+01  2.91976089e+01 -1.91219616e+00  2.91843777e+01  3.74224052e+01 -9.90075874e+00  1.19409523e+01  2.60366611e+01 -2.87844696e+01  5.54425526e+00 -1.06912982e+00  4.25311089e+01  6.93858957e+00 -3.49932861e+01 -1.26211290e+01 -3.25050316e+01  3.38431702e+01 -3.94450798e+01 -8.54807472e+00 -3.05000210e+01  1.40299072e+01 -1.25643420e+00 -3.78161201e+01 -6.24785538e+01 -3.80246782e+00 -2.78650856e+01  6.69966507e+00 -3.57816162e+01 -3.21885757e+01  6.86019516e+00  3.14706955e+01  4.96680784e+00  2.55934410e+01  2.28218384e+01  2.77968712e+01 -3.77630577e+01 -6.44830608e+00 -1.73946609e+01 -7.93138981e+00  5.52771616e+00  2.24999809e+01  2.26205635e+01  2.55261097e+01  2.90146828e+01  3.74401703e+01  8.56201553e+00  3.25501404e+01 -2.79387779e+01  1.19340582e+01  4.73582458e+01  1.17452984e+01 -3.01858883e+01  4.50036001e+00\n",
      " -1.19293966e+01 -1.83577309e+01  5.43629723e+01 -2.63473988e+01 -2.76799450e+01 -4.77719421e+01  3.55072556e+01  1.32258749e+01  3.03684521e+01  4.52331638e+00  1.36393414e+01  5.95930767e+00 -5.80889015e+01  3.35996780e+01 -4.35744781e+01  3.09849339e+01  1.37771568e+01  3.65861473e+01  2.62453804e+01  2.66798325e+01  1.42934504e+01 -1.46692142e+01  1.76739073e+00  2.72339706e+01  1.38659639e+01  1.42953482e+01 -1.47396355e+01  2.00688419e+01 -5.04584045e+01  3.92413235e+00 -3.57212486e+01 -8.59946370e-01 -2.52448654e+01 -2.77004204e+01 -2.01288757e+01  3.99394417e+01 -1.18522902e+01 -4.54013405e+01 -3.21798630e+01  9.84484291e+00 -2.28973236e+01 -2.06103497e+01  4.02064743e+01 -8.09406281e+00 -3.87166328e+01 -2.55891457e+01 -4.14523659e+01 -4.91281450e-01 -1.72123775e+01 -1.88025303e+01  1.44571972e+01 -3.65028000e+01 -1.53731213e+01]\n",
      "Full Embedding 1:\n",
      "[ 3.80567245e+01 -7.93109417e+00 -3.24524345e+01 -3.06410146e+00  7.42445707e+00 -2.85364094e+01  3.80522656e+00 -9.39973450e+00 -9.93508625e+00  6.81154728e+00  1.66052418e+01  7.26188183e+00 -2.70576954e+01  2.34494257e+00  2.55129070e+01 -3.47973938e+01  1.42232962e+01 -2.23608704e+01  1.97827458e-01 -1.18208809e+01  3.17893448e+01  2.61219978e-01  5.16502151e+01 -5.22635803e+01 -4.26811409e+01  2.68874569e+01  4.92067766e+00 -2.36941948e+01 -8.56904697e+00  1.12485065e+01  3.68134460e+01 -6.20116119e+01 -2.85249500e+01  7.14427292e-01  2.10071220e+01  9.74221230e+00 -1.87018204e+01 -1.93583069e+01 -1.86332417e+00 -7.93417120e+00  2.67011185e+01 -6.43783855e+00  1.88519840e+01  1.69657183e+00  5.80380154e+00 -4.65860176e+01 -1.02494307e+01 -2.70782337e+01  1.91007919e+01 -3.13161731e+00  2.57109528e+01  1.98058434e+01  6.66168690e+00  2.76375885e+01  4.00322609e+01 -8.97790623e+00  5.38343859e+00  2.97897549e+01 -4.02928658e+01 -7.92449045e+00 -3.05904541e+01 -8.06316566e+00\n",
      " -3.45649643e+01  2.86995621e+01 -7.36907148e+00  4.06677551e+01  4.74881058e+01 -1.76662040e+00 -3.08766518e+01  4.38862038e+00 -1.77325363e+01 -1.23690615e+01  1.40083294e+01 -2.44414635e+01 -5.62289000e+00  5.03398705e+01  2.56060934e+00  2.49338055e+01 -5.53456163e+00 -1.41631489e+01  5.69747658e+01  9.14788532e+00 -2.93851209e+00 -4.69124680e+01 -9.97335529e+00 -2.89406185e+01  2.15360379e+00 -3.41502075e+01  1.08476524e+01  4.72912490e-01 -1.33676195e+00  2.28575840e+01  4.90871582e+01  1.83465366e+01  5.76879072e+00  2.66225452e+01  2.84749241e+01  7.42191696e+00 -3.16351032e+00  4.79302940e+01 -4.78585386e+00  1.17685223e+00  3.49208260e+01  1.58069551e+00 -3.12167168e+01 -1.70501442e+01  4.00876350e+01 -1.65542698e+01  3.62584801e+01  1.61083813e+01  2.13161907e+01  1.45294542e+01 -1.58440542e+01 -3.06663265e+01  3.05716801e+01  3.69260788e+01  1.40094709e+01 -7.55298805e+00 -1.20033321e+01 -3.24035416e+01 -1.00291920e+01  3.70846443e+01 -7.83420086e+00  1.38661118e+01\n",
      " -3.51155548e+01 -2.33490047e+01 -1.34224319e+01 -2.79565735e+01  1.57743130e+01  4.24823227e+01  1.19368649e+01  1.49138784e+01 -4.04502583e+00  8.80660820e+00  2.24382362e+01 -4.82983475e+01 -2.01919975e+01 -9.27560520e+00  2.40657921e+01  7.61244011e+00  2.02380886e+01 -2.40430698e+01 -1.15888023e+01  1.14485588e+01 -1.74312725e+01  8.94542789e+00 -1.86126366e+01  2.87387981e+01 -7.21624947e+00 -2.91066589e+01 -3.31376028e+00  2.77767735e+01  2.93994484e+01  4.24202766e+01 -1.17833300e+01 -7.93920088e+00  3.14487648e+01  1.31909161e+01  3.12916679e+01  4.33967934e+01  2.86123810e+01  3.10279255e+01  8.66948795e+00 -1.04081182e+01 -4.25973930e+01 -1.51734324e+01 -1.98673267e+01  3.70243835e+01  1.83432388e+01  1.73806477e+01  2.79865913e+01 -3.01877174e+01 -3.61885262e+01 -3.98217964e+01 -1.69930019e+01 -5.02743683e+01  1.35603371e+01  1.14967527e+01  5.02239761e+01 -2.21561699e+01  1.04659986e+01  7.57612944e+00 -1.80978756e+01 -3.21456623e+00  2.32561951e+01  5.92749786e+01\n",
      "  1.96314964e+01  2.42998447e+01 -1.35586643e+01 -2.43938847e+01 -2.96875038e+01 -4.03191376e+01  4.37917747e+01  3.34637871e+01  2.55411587e+01  2.43292942e+01  1.39097795e+01  7.95084667e+00  1.11429214e-01  4.69647141e+01 -2.60620708e+01  3.55435181e+01  1.80642433e+01 -4.20965500e+01 -3.95471153e+01 -1.54284105e+01 -1.70703278e+01  2.95064411e+01  2.44545593e+01  3.61747055e+01 -4.17454147e+01 -2.12702579e+01  2.15713501e+01  3.27035446e+01 -3.62266693e+01 -2.29280910e+01  2.56637325e+01 -2.38807850e+01  3.79926834e+01 -7.52088737e+00  9.79691982e+00 -2.63632202e+01  1.44265900e+01 -1.96385479e+01 -2.32269821e+01 -1.55509167e+01  2.59634953e+01 -3.61304398e+01  2.85754395e+01  1.77552547e+01 -2.11991482e+01  1.32333565e+01 -2.71933193e+01 -6.58139229e+00  3.77128124e+00  1.30419779e+01  3.98628349e+01  1.25176477e+01 -4.05524750e+01  1.61073720e+00 -4.23830299e+01 -3.49332123e+01 -3.67579956e+01  8.65074825e+00  2.53504467e+01  2.70170937e+01 -7.66678381e+00 -3.31178627e+01\n",
      "  4.71609764e+01  1.07051790e+00  3.59730759e+01  1.27612686e+01 -2.44306889e+01 -2.97515163e+01  9.96364021e+00 -2.12455058e+00  1.59429300e+00  3.84464417e+01 -1.07834949e+01  3.75694351e+01  1.08707790e+01 -3.58622322e+01  2.08642044e+01  3.65083504e+01  3.69623137e+00  4.88483620e+00  2.80860500e+01  2.13830090e+01 -4.22696114e+01 -1.00375147e+01 -4.66781759e+00  1.92236042e+01 -1.30896406e+01  5.04928923e+00 -1.29103308e+01 -2.92500877e+01  5.50048599e+01 -1.31752090e+01  1.07476988e+01  4.07990646e+00 -5.82928276e+00 -2.03140640e+01 -1.63465595e+01  2.65174980e+01 -6.49604130e+00  1.06367040e+00 -4.31904869e+01 -2.51341076e+01  9.10523796e+00 -2.95786591e+01 -9.70576668e+00  2.34339275e+01 -8.89089775e+00 -2.37014370e+01  4.78759270e+01  1.24930344e+01 -5.92377520e+00  3.02460432e+00 -1.67646942e+01 -3.08714066e+01 -1.88048115e+01 -2.28198195e+00  5.64311171e+00 -7.21302319e+00 -9.51603889e-01 -3.14358006e+01  3.37811584e+01  9.93672943e+00 -3.69790154e+01  1.70884628e+01\n",
      "  2.05069904e+01 -2.66274948e+01  4.46201401e+01 -1.92478390e+01 -1.76493626e+01 -2.07570972e+01 -5.32011032e+00 -5.02107925e+01  2.10721836e+01 -2.65123520e+01  2.36076393e+01 -6.11200428e+00 -7.36365891e+00 -2.23507690e+01  3.13122768e+01 -1.75675030e+01 -6.39912891e+00  1.54730282e+01 -3.58802795e+01  4.39269352e+00  2.12019901e+01 -5.50725269e+00 -4.24738235e+01  2.21926193e+01 -4.91131353e+00 -1.16362143e+01  1.64764614e+01  3.09964418e-01 -3.32199645e+00  3.62105331e+01  4.37723694e+01  2.81787663e+01 -4.79380655e+00 -4.08718452e+01  1.50603848e+01  6.66000938e+00 -3.07948933e+01  3.26563120e+00  3.01163216e+01 -4.51877356e+00  4.43441772e+01  1.34801493e+01 -1.95137482e+01 -2.71098423e+01  5.53567314e+01 -3.15024052e+01  2.44737625e+01  8.64348698e+00 -3.02802677e+01  2.99593139e+00 -2.23944664e+00 -3.21068573e+01 -2.97717037e+01 -2.29301167e+01  4.85995626e+00  3.85420265e+01 -2.87470760e+01  4.97501907e+01 -1.83255386e+00  3.22547112e+01 -4.45145845e-01  1.27787933e+01\n",
      "  8.01180553e+00  3.36323662e+01 -1.07370052e+01 -2.12646656e+01 -3.27437706e+01 -3.15612965e+01  1.92622890e+01 -1.64577751e+01 -2.13382778e+01  5.86698265e+01  3.35477142e+01  3.70062370e+01  1.91365528e+00 -4.01584015e+01 -2.52624149e+01 -3.91244087e+01 -3.70477180e+01 -1.75012817e+01  4.16142159e+01  3.24338188e+01  2.58192501e+01  7.16738319e+00  1.21280594e+01  7.32269430e+00  1.68952141e+01  1.62460766e+01 -2.40016670e+01  3.30928955e+01  4.20295563e+01 -5.46637573e+01 -7.75574589e+00  2.08026390e+01 -3.53766479e+01 -1.33797798e+01 -2.14540730e+01  2.14543648e+01 -1.85749397e+01  9.43865061e-01  2.23657894e+01 -2.20650139e+01 -1.24814167e+01 -2.63918037e+01 -2.88546038e+00 -3.02376232e+01  1.73913326e+01  3.48584533e+00  2.93966942e+01  3.02342091e+01 -2.54632664e+01 -2.00515862e+01 -2.59839249e+01  4.36979866e+00  1.04643621e+01 -1.01354952e+01  3.96490364e+01  5.11235313e+01  4.81655083e+01 -3.13456178e+00  3.07310772e+01  2.23041744e+01  4.11567268e+01  3.84245949e+01\n",
      "  4.98352814e+01  1.93156281e+01  1.30873013e+01  2.92206497e+01 -1.02572107e+01  2.18883934e+01  3.13176804e+01  2.06276112e+01  1.11507959e+01  2.46593933e+01 -2.27470226e+01 -3.00182891e+00 -3.16117525e+00 -1.81215343e+01  3.51515465e+01  3.50793228e+01 -1.09902554e+01  3.82872734e+01  3.10679054e+01  1.06569309e+01 -5.59621735e+01  2.51801414e+01  1.85833931e+01 -3.72812691e+01  2.41390209e+01 -2.49763107e+01 -2.16682577e+00 -2.93966222e+00 -2.20466175e+01  3.61755104e+01  3.07056580e+01  2.62283077e+01  1.07293739e+01 -8.25617218e+00 -1.24093342e+01  3.67031212e+01 -1.00605907e+01  1.40673780e+01 -2.84293938e+01  3.56304207e+01 -2.09615231e-01 -3.03248386e+01 -4.30971489e+01  3.35303926e+00  3.81847153e+01  2.09652557e+01 -4.89085732e+01  2.39046803e+01 -2.81795616e+01  1.46281462e+01  1.92661076e+01 -1.79809208e+01 -1.97893982e+01 -1.92387176e+00 -1.19478245e+01  2.65673447e+00  1.38262463e+01  3.38443184e+00  2.73827438e+01 -4.01356812e+01  1.81123257e+01 -7.79913855e+00\n",
      "  2.76978645e+01  4.53832512e+01  1.93982792e+01  1.22391195e+01 -1.00149784e+01  1.86908646e+01 -9.94881821e+00  2.49745331e+01  7.82203770e+00  2.11756878e+01 -4.24957123e+01 -2.87816000e+00  8.39968967e+00  5.04288626e+00  2.63286819e+01  1.25717802e+01  8.41851997e+00  4.48913956e+01  1.22866898e+01  2.48625546e+01 -2.96073475e+01 -1.16894417e+01 -8.90994072e-02  5.58821297e+00  3.43081398e+01  2.33184052e+01  9.65304947e+00 -3.15505958e+00 -3.25473137e+01  7.10311556e+00  2.47372131e+01  3.85082550e+01 -3.75318947e+01 -1.84277878e+01  3.01649818e+01  4.30193663e+00  3.34095230e+01  3.22628670e+01 -2.54447765e+01  4.11004066e+01  5.13920097e+01  4.44336548e+01 -3.29052505e+01  1.04017754e+01  2.05279293e+01 -1.45304680e+00 -1.76981030e+01 -4.66584444e+00  2.95870056e+01  1.52671986e+01 -2.41168385e+01 -2.79526958e+01  2.50961552e+01  1.79076805e+01 -2.53502893e+00 -8.22692490e+00 -1.27683210e+01  4.11484108e+01  3.83759956e+01 -3.64709320e+01 -2.20606918e+01  3.21570129e+01\n",
      "  3.29646225e+01  1.74199677e+01 -1.72882442e+01 -3.34946976e+01 -1.34765081e+01 -3.92118607e+01 -4.10614738e+01  2.13891544e+01 -3.02858448e+00  3.25854301e+01 -1.03120432e+01 -7.97699070e+00 -5.32973623e+00  4.10868645e+01  5.22173271e+01 -7.09412432e+00  2.31170292e+01 -5.43284378e+01  3.24462128e+01 -4.15615311e+01  1.24905548e+01 -2.56760616e+01 -2.69089699e+01 -7.02471876e+00 -3.89774094e+01 -2.75956383e+01 -3.05956707e+01 -4.26084328e+01 -3.33005676e+01 -6.53040695e+00 -2.35065212e+01  3.78837204e+01  3.41887131e+01 -2.14563637e+01  4.99180641e+01 -4.70972023e+01  6.60202885e+00  1.45839367e+01 -5.20314255e+01 -5.15179634e+00  3.89413834e+01 -2.07709026e+01 -3.32225075e+01 -2.49918556e+01 -3.74655800e+01 -1.30793409e+01  3.03606262e+01  5.15485535e+01  1.72341137e+01 -5.75010109e+00  3.36066551e+01 -3.09701753e+00 -1.78222656e+01 -3.95253983e+01 -7.39464569e+00 -1.17949123e+01 -5.43425035e+00  3.79180107e+01  1.14818840e+01 -3.01355705e+01  3.58984146e+01 -1.63457489e+01\n",
      "  1.88411546e+00 -2.06699257e+01 -1.58807182e+01  1.63418331e+01 -1.36801186e+01  4.07019186e+00 -9.58816719e+00 -2.36905079e+01  1.35643082e+01 -1.69702969e+01  2.27431469e+01 -4.25429382e+01  1.25293713e+01 -8.06975365e+00 -2.86397686e+01 -5.32176704e+01 -1.87363892e+01 -8.21071148e+00 -4.31938553e+01 -4.51571846e+00  2.24886856e+01 -2.91038456e+01  1.62965584e+01 -1.84064331e+01  5.40589218e+01  8.48601151e+00  7.45214272e+00 -3.91155586e+01 -1.58117857e+01 -1.72684917e+01  3.88174858e+01  3.85878258e+01 -1.82448387e+01  3.88516197e+01 -3.26490517e+01 -3.14900398e+01  3.69526978e+01  2.70923653e+01  1.33990850e+01 -2.90993959e-01  2.44005604e+01  3.95226898e+01  4.22583122e+01  3.43700027e+01 -3.78259506e+01  1.93200245e+01 -2.37215195e+01  1.36456318e+01  1.09922438e+01  1.49042110e+01  2.54852982e+01  1.40750380e+01  2.60609913e+01  2.66740837e+01  5.09944191e+01 -3.50834694e+01  2.18651414e-01  1.23067369e+01  9.71116734e+00 -1.83481598e+01 -1.35157290e+01 -1.55951464e+00\n",
      "  1.10663891e+00 -2.03158627e+01 -1.46669712e+01 -3.99823074e+01  5.91701603e+00 -9.65619087e+00  9.97198582e-01 -3.56041574e+00 -2.29164543e+01  3.01975880e+01 -1.20907183e+01 -4.09393311e-02 -3.87969933e+01 -5.29853702e-01 -7.06188965e+00  3.72419624e+01 -6.31727791e+00 -5.20502234e+00 -1.02760353e+01 -1.58668928e+01 -4.57183990e+01 -4.31157074e+01 -3.35445023e+01  9.89628220e+00 -2.68732033e+01 -3.44693680e+01  5.66518259e+00  1.59857988e+01 -1.68965912e+01  1.19330931e+01 -3.51726952e+01  3.39956856e+01  1.64865494e+01 -3.96550941e+01  1.44768877e+01  2.88272934e+01 -1.22302790e+01 -5.28895855e+00 -2.08378468e+01 -5.32843704e+01 -1.72085304e+01 -8.52765560e+00  4.96376228e+00 -1.17613792e+01  1.13802757e+01  4.28004265e-01 -2.89435005e+01  2.47322292e+01  6.02104092e+00 -1.79432812e+01  2.25905895e+01 -9.89037132e+00 -4.24249649e+00  9.49442673e+00  1.13161821e+01  1.87718353e+01  6.73059464e+00 -2.75166149e+01 -4.14306221e+01  1.91282511e+00 -1.01141281e+01 -1.54194584e+01\n",
      " -1.44009743e+01 -4.21543579e+01  2.48991680e+01  4.14164658e+01  2.21402416e+01 -2.05936890e+01 -9.41682243e+00 -1.03059092e+01 -1.35643826e+01 -1.79984798e+01 -2.19930763e+01 -1.43042669e+01  2.53860130e+01 -2.52167225e+01 -1.60728588e+01 -2.95021462e+00 -2.78986549e+01 -1.36644650e+01 -1.21462326e+01  4.27914581e+01 -3.05539246e+01 -1.46991377e+01  4.25650368e+01 -3.32389412e+01  3.19323463e+01  4.25974884e+01 -2.75559006e+01  2.58001995e+01  1.44017277e+01 -1.96651192e+01 -9.29542828e+00 -6.81739521e+00 -2.16675892e+01  4.46217346e+00  3.96451187e+01  8.95230007e+00  3.43985748e+01  2.02086163e+01 -3.38044000e+00 -1.74409962e+01  3.36524887e+01 -3.13671207e+01  2.45314903e+01 -4.10226250e+01  6.51740170e+00  1.00031710e+01 -1.06555214e+01 -2.28230171e+01  4.28300819e+01 -1.71473522e+01 -1.33728132e+01  2.47053185e+01 -3.14947739e+01 -1.11705055e+01 -5.09025650e+01 -1.02745457e+01 -1.64562855e+01 -2.87426434e+01  1.20935621e+01 -9.14018250e+00  7.23664379e+00 -3.70822296e+01\n",
      " -2.27807255e+01  1.93701439e+01 -5.84195566e+00 -3.81181183e+01  2.63651276e+01 -5.01503639e+01  3.39292717e+00 -2.50699735e+00  3.75997849e+01 -1.10374475e+00 -7.79306412e+00 -7.42287636e-02  1.75401402e+01  1.04725242e-01 -1.90102940e+01  8.97533512e+00  2.25065002e+01  5.29889774e+00 -1.60347443e+01 -1.24727859e+01 -4.35584450e+01  8.73443317e+00  1.44418545e+01 -8.04575825e+00  1.03908072e+01 -3.34308090e+01  1.83827229e+01  4.09237251e+01 -2.90456295e+00 -1.49816628e+01  1.48055973e+01 -1.38679667e+01 -1.44342337e+01 -3.91528854e+01  2.46452599e+01 -6.85463810e+00  3.48850656e+00 -4.35759211e+00  1.54066992e+01  9.34141254e+00 -1.98009663e+01  2.30928993e+00 -6.66488552e+00 -5.77788687e+00  2.13902130e+01  9.80003166e+00 -3.54613876e+01 -8.71295738e+00 -6.43878937e-01  1.90992203e+01 -2.21447716e+01  3.24102592e+01  2.75748177e+01  2.59709530e+01 -2.31224213e+01 -2.56294804e+01 -3.83935699e+01 -8.13549328e+00 -2.09624233e+01  1.51606627e+01 -5.53928995e+00  1.37531891e+01\n",
      " -4.64028263e+00 -2.84177990e+01  1.84718075e+01  2.02322555e+00 -2.82864914e+01 -3.57775116e+01  1.45751944e+01 -3.47757530e+01 -3.85295677e+01  2.51453304e+00 -6.06546736e+00  1.99923935e+01  5.03610802e+01  2.87959442e+01  5.03976326e+01  3.48447838e+01  3.97082481e+01 -3.02808037e+01  4.42508888e+01  8.68386173e+00 -1.53355684e+01 -5.52591610e+00 -4.17735367e+01  3.36165924e+01 -3.40863571e+01 -4.61654997e+00 -1.93543301e+01  3.11187038e+01  1.46196280e+01 -1.92555466e+01  3.84777045e+00 -7.40588188e+00 -2.01511040e+01 -2.84728527e+00  3.50982170e+01  8.33352566e-01 -1.10630207e+01 -2.81839681e+00  4.30927753e+00 -8.20040226e+00  3.29427757e+01  3.53239555e+01  1.40452766e+00  5.44136467e+01 -3.40622826e+01 -1.56171818e+01  1.93400898e+01 -1.32939281e+01  5.11166191e+01  2.97300949e+01  2.98030663e+01 -1.55089808e+01 -2.23985653e+01 -4.36345291e+00 -3.34901428e+01 -4.24484482e+01  3.39827576e+01 -2.52102947e+01 -3.77674484e+01  2.33714128e+00 -3.22022591e+01 -3.37918854e+01\n",
      " -2.63144417e+01 -2.48856297e+01  3.29836044e+01  8.83729517e-01 -3.42432098e+01  2.76552620e+01 -1.59129448e+01  2.45235767e+01 -1.02571497e+01 -9.09160709e+00  2.12615204e+01  8.54707432e+00  8.19224453e+00  2.55580196e+01 -4.60615587e+00  7.44991684e+00 -6.53848267e+00 -2.50402374e+01 -4.25480499e+01 -4.15713263e+00 -6.58800840e-01 -1.40681496e+01  2.25557709e+01 -1.58676968e+01 -2.29577160e+01 -2.10700378e+01  8.19607735e+00  2.36247969e+00  2.43541832e+01 -2.56828403e+00  1.16457996e+01 -1.89963894e+01  1.81407089e+01 -3.25620842e+01  1.51191025e+01  1.44168139e+01  3.48660736e+01 -2.37873688e+01 -1.39842091e+01  4.96658096e+01  3.19261913e+01  8.18212605e+00 -3.10137291e+01  9.62218475e+00  3.44412537e+01 -1.97873211e+01 -4.73718185e+01 -3.19731407e+01  2.43028679e+01  1.08217506e+01  1.23128023e+01 -9.81692123e+00 -3.11831284e+01  7.71003771e+00  1.25703592e+01  3.35472703e-01 -1.27796888e-01  1.86852055e+01  1.87736588e+01  1.81340466e+01 -3.37991180e+01  1.90893345e+01\n",
      "  1.72783508e+01 -1.17607460e+01 -1.05310087e+01 -4.04341660e+01  2.16313591e+01  1.04712486e+01 -2.80265388e+01  2.94177361e+01 -1.19773436e+01  3.57446213e+01 -9.23466492e+00  1.05684071e+01 -1.55655727e+01 -1.22797146e+01 -4.61203613e+01  4.08371849e+01 -1.67039356e+01  3.09591923e+01 -7.06901550e-01 -2.82742920e+01  3.15447545e+00 -1.52405577e+01 -2.09190788e+01  4.08026123e+01 -2.28289642e+01  2.15951371e+00 -2.67778950e+01  3.26308403e+01 -4.01939888e+01 -1.50885487e+01 -3.67412138e+00  6.42055988e-01 -3.80351782e+00  1.38686094e+01  1.21997957e+01 -4.96732235e+00 -1.00105209e+01  5.42136002e+00 -5.25603981e+01 -4.95043144e+01  1.58874273e-01  4.59583044e+00 -8.18703270e+00  2.45090389e+00 -1.07539692e+01  1.44721098e+01 -1.41525805e+00  5.28955154e+01  4.71234512e+00  2.29167137e+01  3.46162148e+01 -6.15068207e+01 -3.12352371e+01 -3.56945992e+01 -7.82990456e+00  2.34578018e+01  1.21661797e+01 -1.58950639e+00  1.58101635e+01  2.58430988e-01 -7.18654156e+00  5.08899345e+01\n",
      " -2.02657509e+01 -2.54621029e+01 -4.91070595e+01 -4.55595398e+01 -1.42844810e+01  3.40547371e+01  2.88958502e+00 -8.42211723e+00  1.57736750e+01 -6.60861664e+01 -1.68063374e+01 -1.31546555e+01  2.87918987e+01 -2.80257263e+01 -2.95838871e+01  3.20068474e+01 -1.32405090e+01  1.68216777e+00 -8.45486069e+00  3.52383614e+01 -3.22103262e+00  1.41240997e+01  3.78398514e+01  3.96447563e+01  3.26308870e+00 -2.58893318e+01  5.93280649e+00 -1.11842299e+01  2.79990044e+01 -8.77616024e+00  4.14201622e+01  1.34152403e+01 -7.74781847e+00 -7.59489179e-01  1.15127335e+01 -2.01887455e+01 -5.43920517e+01 -2.97525272e+01  3.16834431e+01  1.77462780e+00  1.28163366e+01  2.55720139e+00  3.38170357e+01 -3.82304688e+01 -3.51032677e+01 -6.79957724e+00 -4.28905296e+01 -2.61848793e+01  1.28616152e+01  2.85832157e+01 -2.90863342e+01 -1.05254774e+01 -9.91198063e-01 -4.23770218e+01  5.08706665e+00  3.19087181e+01  1.52461405e+01 -3.10860996e+01 -1.11494684e+01 -2.47135830e+01  3.55176659e+01  7.69848251e+00\n",
      " -4.38424606e+01 -1.32667217e+01 -2.74037123e-01 -3.74196167e+01 -3.26249466e+01  2.03577118e+01 -2.37119236e+01  6.41582918e+00  4.10016489e+00 -3.28563805e+01  3.77325974e+01 -3.52804494e+00 -1.99805412e+01 -8.01656151e+00 -1.54161053e+01 -1.78951550e+01  5.42891350e+01  7.59982681e+00  2.06884098e+01 -3.90078354e+01  3.23506927e+01  6.39490461e+00 -2.18485909e+01 -1.99230742e+00  1.97089119e+01  1.88821125e+01 -1.02514057e+01  3.24398499e+01 -8.35340214e+00 -6.05379257e+01 -1.75662079e+01 -9.44964123e+00 -1.44794836e+01  1.50016460e+01 -2.01816654e+01 -4.05790758e+00 -1.78632355e+01 -2.43012104e+01 -2.76177254e+01  3.82497787e-01 -2.27606792e+01  1.30368538e+01 -5.06912470e+00 -1.45735645e+01 -2.51398277e+00 -6.17612648e+00 -2.80292816e+01  2.59090862e+01  1.85516415e+01  3.83386993e+00 -4.88969078e+01  3.07558861e+01 -3.20478439e+00 -1.60937843e+01  1.60177517e+01 -3.35527277e+00  4.04797935e+01 -1.38445024e+01  3.47331963e+01  3.15514183e+01 -3.35358963e+01  3.85605011e+01\n",
      "  1.95292130e+01 -9.48446465e+00  3.92034798e+01 -1.19113731e+01  1.06940498e+01 -4.36615829e+01 -3.98714867e+01 -5.91292858e+00 -2.71784782e+01  3.65047646e+00  1.73726196e+01  1.62615490e+01 -3.78975525e+01 -3.64324875e+01  6.99028969e-01 -2.31291056e+00 -3.43607712e+01  3.89311714e+01 -3.38795242e+01 -1.39107237e+01 -3.33073139e+00 -3.70091782e+01 -9.40838814e+00  4.37260666e+01  1.75705261e+01 -3.42798462e+01  1.98831635e+01  6.18062878e+00 -2.19372025e+01  1.61506538e+01  1.76143665e+01  1.09443760e+01 -3.33256035e+01  1.10013008e+01 -2.42185898e+01  2.11518478e+01 -6.02029324e+00  1.88999214e+01 -7.58560276e+00  4.53259087e+01  9.84319878e+00 -2.23814225e+00 -2.13273735e+01 -6.58340645e+00  8.40041542e+00 -1.93693962e+01  2.54310951e+01  1.30097413e+00  2.90643005e+01  1.78370273e+00  3.74297523e+01  2.24217415e+01 -3.76359291e+01 -2.22110558e+00 -5.15549736e+01 -3.97166672e+01  9.77345848e+00  1.90739632e+01 -4.49942627e+01  2.58825474e+01 -7.23001480e+00  5.95870094e+01\n",
      " -4.67402077e+00 -3.13066244e+00  9.11880875e+00  2.91732044e+01  4.27184105e-02  2.00596409e+01  2.55041599e+00 -8.74982357e+00 -2.09276009e+01  1.63444500e+01  1.50133533e+01  1.07181621e+00  1.23832283e+01  1.40424976e+01 -3.50921974e+01 -4.36914024e+01  1.59839382e+01 -2.59204078e+00  3.25034256e+01  6.54986858e+00 -1.35023527e+01 -2.21567478e+01  3.05871181e+01  1.77488461e+01  1.34262190e+01 -1.62602425e+01  4.87931290e+01  4.20933952e+01 -3.78183675e+00  2.49077053e+01 -1.38822651e+01  1.74478569e+01  3.16521320e+01 -8.03070164e+00 -3.24426117e+01  1.32714157e+01  1.66003513e+01 -1.50286674e+01  1.98773537e+01 -4.26296854e+00 -3.00511532e+01 -2.89529972e+01 -2.29549007e+01  1.94868279e+01 -3.61336350e+00 -1.65626240e+01  6.17327642e+00 -1.54304540e+00  3.15755959e+01  5.89354181e+00  3.56856003e+01  1.60361791e+00  7.13365173e+00 -1.84810781e+00  5.04815245e+00 -2.89859314e+01  5.71370468e+01  4.90654602e+01 -2.83923893e+01 -9.89497280e+00  1.13867054e+01  2.42384205e+01\n",
      "  3.60958710e+01  4.70556412e+01  1.49942236e+01 -6.27021599e+00  1.29535818e+01 -1.93573570e+01  6.01516724e+01  8.38474464e+00 -1.23440657e+01 -2.69282627e+01  2.91976089e+01 -1.91219616e+00  2.91843777e+01  3.74224052e+01 -9.90075874e+00  1.19409523e+01  2.60366611e+01 -2.87844696e+01  5.54425526e+00 -1.06912982e+00  4.25311089e+01  6.93858957e+00 -3.49932861e+01 -1.26211290e+01 -3.25050316e+01  3.38431702e+01 -3.94450798e+01 -8.54807472e+00 -3.05000210e+01  1.40299072e+01 -1.25643420e+00 -3.78161201e+01 -6.24785538e+01 -3.80246782e+00 -2.78650856e+01  6.69966507e+00 -3.57816162e+01 -3.21885757e+01  6.86019516e+00  3.14706955e+01  4.96680784e+00  2.55934410e+01  2.28218384e+01  2.77968712e+01 -3.77630577e+01 -6.44830608e+00 -1.73946609e+01 -7.93138981e+00  5.52771616e+00  2.24999809e+01  2.26205635e+01  2.55261097e+01  2.90146828e+01  3.74401703e+01  8.56201553e+00  3.25501404e+01 -2.79387779e+01  1.19340582e+01  4.73582458e+01  1.17452984e+01 -3.01858883e+01  4.50036001e+00\n",
      " -1.19293966e+01 -1.83577309e+01  5.43629723e+01 -2.63473988e+01 -2.76799450e+01 -4.77719421e+01  3.55072556e+01  1.32258749e+01  3.03684521e+01  4.52331638e+00  1.36393414e+01  5.95930767e+00 -5.80889015e+01  3.35996780e+01 -4.35744781e+01  3.09849339e+01  1.37771568e+01  3.65861473e+01  2.62453804e+01  2.66798325e+01  1.42934504e+01 -1.46692142e+01  1.76739073e+00  2.72339706e+01  1.38659639e+01  1.42953482e+01 -1.47396355e+01  2.00688419e+01 -5.04584045e+01  3.92413235e+00 -3.57212486e+01 -8.59946370e-01 -2.52448654e+01 -2.77004204e+01 -2.01288757e+01  3.99394417e+01 -1.18522902e+01 -4.54013405e+01 -3.21798630e+01  9.84484291e+00 -2.28973236e+01 -2.06103497e+01  4.02064743e+01 -8.09406281e+00 -3.87166328e+01 -2.55891457e+01 -4.14523659e+01 -4.91281450e-01 -1.72123775e+01 -1.88025303e+01  1.44571972e+01 -3.65028000e+01 -1.53731213e+01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Disable truncation\n",
    "np.set_printoptions(threshold=np.inf, linewidth=1000)\n",
    "\n",
    "for i, emb in enumerate(val_embeddings):\n",
    "    print(f\"Full Embedding {i}:\\n{emb}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

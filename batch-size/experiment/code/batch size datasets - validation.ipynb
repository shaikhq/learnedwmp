{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627f35d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/shaikhq/opt/anaconda3/lib/python3.8/site-packages (3.0.10)\n",
      "Requirement already satisfied: et_xmlfile in /Users/shaikhq/opt/anaconda3/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead52abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c77c19",
   "metadata": {},
   "source": [
    "# check the count in batch = 2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c71205a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_batch_count(batch_size):\n",
    "    print('checking the train file with batch size ', batch_size)\n",
    "    print('batch size: ', batch_size)\n",
    "    df = pd.read_csv('data/train_workloads_final_110_clusters_' + str(batch_size) + '_batch.csv')\n",
    "    \n",
    "    #drop db2 and actual columns\n",
    "    df1 = df.copy().drop(columns=['db2', 'actual'])\n",
    "    print('no columns after dropping db2 and actual: ', df1.shape[1])\n",
    "\n",
    "    # add the column values from the remaining columns to get the count of query instances in each workload \n",
    "    # and save the count in a new column, count\n",
    "    df1['count'] = df1[list(df1.columns)].sum(axis=1)\n",
    "\n",
    "    df1 = df1.astype({'count' : 'int32'})\n",
    "\n",
    "    #print the number of workloads that don't have the expected number of queries\n",
    "    print('no of workloads without the required number of queries: ', df1[df1['count'] != batch_size].shape[0])\n",
    "    \n",
    "    print('most frequent values: ', df1['count'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "159b2dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  5 10 15 20 25 30 35 40 45 50]\n"
     ]
    }
   ],
   "source": [
    "df_batches = pd.read_excel('../plot/batchsize_4.xlsx')\n",
    "batch_sizes = df_batches['Batch_Size'].values\n",
    "\n",
    "print(batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f35a81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking the train file with batch size  1\n",
      "batch size:  1\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  1\n",
      "\n",
      "\n",
      "checking the train file with batch size  2\n",
      "batch size:  2\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  2\n",
      "\n",
      "\n",
      "checking the train file with batch size  3\n",
      "batch size:  3\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  3\n",
      "\n",
      "\n",
      "checking the train file with batch size  5\n",
      "batch size:  5\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  5\n",
      "\n",
      "\n",
      "checking the train file with batch size  10\n",
      "batch size:  10\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  10\n",
      "\n",
      "\n",
      "checking the train file with batch size  15\n",
      "batch size:  15\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  15\n",
      "\n",
      "\n",
      "checking the train file with batch size  20\n",
      "batch size:  20\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  20\n",
      "\n",
      "\n",
      "checking the train file with batch size  25\n",
      "batch size:  25\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  25\n",
      "\n",
      "\n",
      "checking the train file with batch size  30\n",
      "batch size:  30\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  30\n",
      "\n",
      "\n",
      "checking the train file with batch size  35\n",
      "batch size:  35\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  35\n",
      "\n",
      "\n",
      "checking the train file with batch size  40\n",
      "batch size:  40\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  40\n",
      "\n",
      "\n",
      "checking the train file with batch size  45\n",
      "batch size:  45\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  45\n",
      "\n",
      "\n",
      "checking the train file with batch size  50\n",
      "batch size:  50\n",
      "no columns after dropping db2 and actual:  110\n",
      "no of workloads without the required number of queries:  0\n",
      "most frequent values:  50\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [1, 2,  3,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "for b in batch_sizes:\n",
    "    check_batch_count(b)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d413b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
